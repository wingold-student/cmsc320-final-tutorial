{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Computer Science versus Business Management Introductory Course Professors Reviews and Their Trends Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "William Ingold, Erik Kelemen, Ashish Manda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Introductory Course Professors From UMD.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "professors_url = \"https://api.umd.io/v1/professors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import path\n",
    "\n",
    "cmsc_professor_names_filepath = './data/cmsc_professor_names.csv'\n",
    "bmgt_professor_names_filepath = './data/bmgt_professor_names.csv'\n",
    "\n",
    "have_cmsc_professors = path.exists(cmsc_professor_names_filepath)\n",
    "have_bmgt_professors = path.exists(bmgt_professor_names_filepath)\n",
    "\n",
    "def read_professor_name_data(professor_filepath):\n",
    "    \"\"\"Reads the professor names and their courses from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professor_filepath: String holding a filepath to the professor csv file.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of professor names to a set of courses they have taught.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(professor_filepath, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "\n",
    "        professors = {}\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if line_count != 0:\n",
    "                professors[row['name']] = set([course for course in row['courses'].split(' ')])\n",
    "            line_count += 1\n",
    "\n",
    "        return professors\n",
    "\n",
    "def save_professor_data(professors, filepath):\n",
    "    \"\"\"Saves the professor names and their courses to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professors: A dictionary of professor name keys and a set of courses for values.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = ['name', 'courses']\n",
    "    try:\n",
    "        with open(filepath, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for name, courses in professors.items():\n",
    "                writer.writerow({'name': name, 'courses': ' '.join(courses)})\n",
    "                \n",
    "    except IOError:\n",
    "        print(\"Error in writing the CSV file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_professors_for_courses(course_ids):\n",
    "    \"\"\"Gets all the professors for the given course_ids and returns a list of them.\n",
    "    \n",
    "    Args:\n",
    "        course_ids: A list of course ids (e.g. ['CMSC216', CMSC250']).\n",
    "        \n",
    "    Returns:\n",
    "        List of professors that teach the given courses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    professors = {}\n",
    "    \n",
    "    for course_id in course_ids:\n",
    "        params = {'course_id': course_id}\n",
    "\n",
    "        response = requests.get(professors_url, params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "\n",
    "            for item in response.json():\n",
    "                name = item['name']\n",
    "\n",
    "                if name in professors:\n",
    "                    professors[name].add(course_id)\n",
    "                else:\n",
    "                    professors[name] = {course_id}\n",
    "\n",
    "    return professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Science Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_bmgt_professors = False \n",
    "have_cmsc_professors = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fawzi Emad': {'CMSC131', 'CMSC250', 'CMSC132'}, 'Ilchul Yoon': {'CMSC131', 'CMSC216', 'CMSC132'}, 'Nelson Padua-Perez': {'CMSC131', 'CMSC216', 'CMSC132'}, 'Pedram Sadeghian': {'CMSC131', 'CMSC132'}, 'Anwar Mamat': {'CMSC132'}, 'Laurence Herman': {'CMSC216', 'CMSC132'}, 'A Shankar': {'CMSC216'}, 'Aditya Acharya': {'CMSC250'}, 'Alexander Brassel': {'CMSC250'}, 'Clyde Kruskal': {'CMSC250'}, 'David Sekora': {'CMSC250'}, 'Donald Perlis': {'CMSC250'}, 'Jason Filippou': {'CMSC250'}, 'Mohammad Nayeem Teli': {'CMSC250'}, 'Roger Eastman': {'CMSC250'}}\n"
     ]
    }
   ],
   "source": [
    "cmsc_course_ids = [\"CMSC131\", \"CMSC132\", \"CMSC216\", \"CMSC250\"]\n",
    "\n",
    "if not have_cmsc_professors:\n",
    "    cmsc_professors = get_professors_for_courses(cmsc_course_ids)\n",
    "    save_professor_data(cmsc_professors, cmsc_professor_names_filepath)\n",
    "    have_cmsc_professors = True\n",
    "else: \n",
    "    cmsc_professors = read_professor_name_data(cmsc_professor_names_filepath)\n",
    "\n",
    "if not cmsc_professors:\n",
    "    print(\"Error response from umd.io API\")\n",
    "\n",
    "if 'Iason Filippou' in cmsc_professors:\n",
    "    cmsc_professors.pop('Iason Filippou') # A typo of Jason Filippou from the database\n",
    "    \n",
    "print(cmsc_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Management Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hugh Turner': {'BMGT110'}, 'Jeff Miller': {'BMGT110'}, 'Cody Hyman': {'BMGT220'}, 'Laurel Mazur': {'BMGT221', 'BMGT220'}, 'Progyan Basu': {'BMGT220'}, 'Viktoriya Zotova': {'BMGT220'}, 'Gary Bulmash': {'BMGT221'}, 'Gerald Ward': {'BMGT221'}, 'Ai Ren': {'BMGT230'}, 'Daehoon Noh': {'BMGT230'}, 'Erich Studer-Ellis': {'BMGT230'}, 'Huan Cao': {'BMGT230'}, 'Radu Lazar': {'BMGT230'}, 'Shubham Akshat': {'BMGT230'}, 'Ziwei Cao': {'BMGT230'}}\n"
     ]
    }
   ],
   "source": [
    "bmgt_course_ids = [\"BMGT110\", \"BMGT220\", \"BMGT221\", \"BMGT230\"]\n",
    "\n",
    "if not have_bmgt_professors:\n",
    "    bmgt_professors = get_professors_for_courses(bmgt_course_ids)\n",
    "    save_professor_data(bmgt_professors, bmgt_professor_names_filepath)\n",
    "    have_bmgt_professors = True\n",
    "else:\n",
    "    bmgt_professors = read_professor_name_data(bmgt_professor_names_filepath)\n",
    "\n",
    "if not bmgt_professors:\n",
    "    print(\"Error response from umd.io API\")\n",
    "\n",
    "print(bmgt_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ratemyprofessor_url = \"https://www.ratemyprofessors.com/search.jsp\"\n",
    "\n",
    "params = {'queryoption':'HEADER', 'schoolID':'1270', 'queryBy':'teacherName', 'schoolName':'University+of+Maryland'}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\",\n",
    "    \"Access-Control-Allow-Origin\": \"*\",\n",
    "    \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "    \"Access-Control-Allow-Methods\": \"GET\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rmp_professor_url(html_doc):\n",
    "    \"\"\"Finds the professor's URL on the search page and returns it.\n",
    "    \n",
    "    Args:\n",
    "        html_doc: A string containing an HTML document.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page (if found).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    partial_url = soup.find('li', class_='listing PROFESSOR').find('a', href=True)\n",
    "    \n",
    "    if partial_url:\n",
    "        main_url = \"https://www.ratemyprofessors.com\"\n",
    "        return main_url + partial_url['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rmp_for_professor_url(professor_name, headers, params):\n",
    "    \"\"\"Queries RateMyProfessor for the professor, given the parameters and headers.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: The <first name> <last name> of the professor.\n",
    "        headers: Dictionary of headers for the get request.\n",
    "        params: Dictionary of parameters for the get request.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page after searching for it (if found).\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    params['query'] = professor_name\n",
    "    \n",
    "    response = requests.get(ratemyprofessor_url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return find_rmp_professor_url(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_stats(page_text):\n",
    "    \"\"\"Parses the professor's stats from their page and returns them. Namely their overall rating, \n",
    "    how many would take again, overall difficulty and how many ratings they have on RateMyProfessor.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing their rating, take again percentage, difficulty rating, and rating count.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    rating_score = soup.select('div[class*=\"RatingValue__Numerator\"]')[0].text\n",
    "    \n",
    "    feedback = soup.select('div[class*=\"TeacherFeedback__StyledTeacherFeedback\"]')[0].select('div[class*=\"FeedbackItem__FeedbackNumber\"]')\n",
    "    \n",
    "    take_again = feedback[0].text\n",
    "    difficulty = feedback[1].text\n",
    "    \n",
    "    rating_count = soup.select('div[class*=\"RatingValue__NumRatings\"]')[0].select('a')[0].text\n",
    "    rating_count = ''.join([x for x in rating_count if x.isdigit()])\n",
    "    \n",
    "    return {'rating': rating_score, 'take_again': take_again, 'difficulty': difficulty, 'rating_count': rating_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_top_tags(page_text):\n",
    "    \"\"\"Parses and returns the professor's top tags.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tags describing the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    tags = []\n",
    "    unparsed_tags = soup.select('div[class*=\"TeacherTags__TagsContainer\"]')[0].select('span')\n",
    "    \n",
    "    \n",
    "    for tag in unparsed_tags:\n",
    "        tags.append(tag.text)\n",
    "        \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need Selenium because Javascript hides more reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Firefox(executable_path='./bin/geckodriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_rmp_reviews(page_url):\n",
    "    \"\"\"Loads all the reviews for a given porfessor and returns the text of all of them.\n",
    "    \n",
    "    Args:\n",
    "        page_url: The URL for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the HTML for all the reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # RateMyProfessors has a cookies pop up that overlays the website, it needs to be closed first\n",
    "    time.sleep(0.5)\n",
    "    close_cookies = driver.find_elements(By.XPATH, '//button[text()=\"Close\"]')\n",
    "    \n",
    "    if close_cookies:\n",
    "        close_cookies[0].click()\n",
    "        \n",
    "    load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "    \n",
    "    # RateMyProfessors paginates the reviews via Javascript, so we must continually load more while the button is available\n",
    "    while load_more:\n",
    "        load_more[0].click()\n",
    "        time.sleep(1)\n",
    "        load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "        \n",
    "    return driver.find_element_by_id('ratingsList')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rating_header(soup):\n",
    "    \"\"\"Parses and returns the rating header for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the course and date for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_header = soup.select('div[class*=\"RatingHeader__StyledHeader\"]')[0]\n",
    "    course = rating_header.select('div[class*=\"RatingHeader__StyledClass\"]')[0].text.strip()\n",
    "    date = rating_header.select('div[class*=\"TimeStamp__StyledTimeStamp\"]')[0].text.strip()\n",
    "    \n",
    "    return {'course': course, 'date': date}\n",
    "\n",
    "def parse_meta_data(soup):\n",
    "    \"\"\"Parses and returns the meta data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data (e.g. Would Take Again) for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    course_meta = soup.select('div[class*=\"CourseMeta__StyledCourseMeta\"]')[0]\n",
    "    review_meta_data = {}\n",
    "\n",
    "    for meta_div in course_meta.select('div'):\n",
    "        meta_data = meta_div.text.split(':')\n",
    "        meta_name = meta_data[0].strip()\n",
    "        meta_value = meta_data[1].strip()\n",
    "\n",
    "        review_meta_data[meta_name] = meta_value\n",
    "\n",
    "    return review_meta_data\n",
    "\n",
    "def parse_rating_data(soup):\n",
    "    \"\"\"Parses and returns the rating data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the rating data for the quality and difficulty for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_values_text = soup.select('div[class*=\"RatingValues__StyledRatingValues\"]')[0].select('div[class*=\"RatingValues__RatingValue\"]')\n",
    "    quality = rating_values_text[0].text\n",
    "    difficulty = rating_values_text[1].text\n",
    "\n",
    "    rating_data = {'quality': quality, 'difficulty': difficulty}\n",
    "    \n",
    "    return rating_data\n",
    "\n",
    "def parse_review_tags(soup):\n",
    "    \"\"\"Parses and returns the tags for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list containing the tags for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_container = soup.select('div[class*=\"RatingTags__StyledTags\"]')\n",
    "    \n",
    "    if tag_container: # Since not all reviews add tags\n",
    "        unparsed_tags = tag_container[0].select('span')\n",
    "\n",
    "        tags = []\n",
    "        for tag in unparsed_tags:\n",
    "            tags.append(tag.text)\n",
    "\n",
    "        return tags\n",
    "    \n",
    "def parse_thumb_scoring(soup):\n",
    "    \"\"\"Parses and returns the thumb scoring data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the thumb scoring data for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    thumb_container = soup.select('div[class*=\"RatingFooter__StyledRatingFooter\"]')[0].select('div[class*=\"RatingFooter__HelpTotal\"]')\n",
    "\n",
    "    thumb_up = thumb_container[0].text\n",
    "    thumb_down = thumb_container[1].text\n",
    "    thumb_data = {'thumb-up': thumb_up, 'thumb-down': thumb_down}\n",
    "\n",
    "    return thumb_data\n",
    "\n",
    "def parse_review_text(soup):\n",
    "    \"\"\"Parses and returns the review body text for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the review text for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_text = soup.select('div[class*=\"Comments__StyledComments\"]')[0].text\n",
    "    \n",
    "    return review_text\n",
    "    \n",
    "def parse_single_rmp_review(review_item, courses):\n",
    "    \"\"\"Parses and returns all data for a single review.\n",
    "    Namely it returns: Meta data, rating data, tags, thumb_scoring, and review text.\n",
    "    \n",
    "    Args:\n",
    "        review_item: A single review list item containing all the appropraite HTML.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data, rating data, tags, thumb_scoring, and review text\n",
    "        for a single review.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(review_item, 'html.parser')\n",
    "    \n",
    "    course_and_date = parse_rating_header(soup)\n",
    "    \n",
    "    # TODO: Loses course reviews like 'CMSC131CMSC132' where students combined multiple courses they took\n",
    "    if course_and_date['course'] in courses:\n",
    "        \n",
    "        # Meta data\n",
    "        meta_data = parse_meta_data(soup)\n",
    "        \n",
    "        # Rating data\n",
    "        rating_data = parse_rating_data(soup)\n",
    "        \n",
    "        # Tags \n",
    "        tags = parse_review_tags(soup)\n",
    "        \n",
    "        # Thumb Scoring\n",
    "        thumb_scoring = parse_thumb_scoring(soup)\n",
    "        \n",
    "        # Review body\n",
    "        review_text = parse_review_text(soup)\n",
    "        \n",
    "        return {'meta_data': meta_data, 'rating_data': rating_data, 'tags': tags, 'thumb_scoring': thumb_scoring, 'review_text': review_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_rmp_reviews(reviews_list_html):\n",
    "    soup = BeautifulSoup(reviews_list_html, 'html.parser')\n",
    "\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Science Professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ratemyprofessors.com/ShowRatings.jsp?tid=313062\n"
     ]
    }
   ],
   "source": [
    "fawzi_url = query_rmp_for_professor_url('Fawzi Emad', headers, params)\n",
    "print(fawzi_url)\n",
    "\n",
    "response = requests.get(fawzi_url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split for testing purposes, don't want to query the page multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rating': '4.4', 'take_again': '83%', 'difficulty': '3.1', 'rating_count': '114'}\n",
      "['Amazing lectures', 'Respected', \"Skip class? You won't pass.\", 'Beware of pop quizzes', 'Hilarious']\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(get_rmp_prof_stats(response.text))\n",
    "    print(get_rmp_prof_top_tags(response.text))\n",
    "    \n",
    "else:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta_data': {'Would Take Again': 'Yes', 'Grade': 'A', 'Textbook': 'No', 'Online Class': 'Yes'}, 'rating_data': {'quality': '5.0', 'difficulty': '1.0'}, 'tags': ['Hilarious', 'Lecture heavy'], 'thumb_scoring': {'thumb-up': ' 0', 'thumb-down': ' 0'}, 'review_text': 'Fawzi is a legend'}\n"
     ]
    }
   ],
   "source": [
    "single_review = \"\"\"\n",
    "<div class=\"Rating__RatingBody-sc-1rhvpxz-0 dGrvXb\"><div class=\"RatingHeader__StyledHeader-sc-1dlkqw1-0 uBHCj\"><div class=\"RatingHeader__ClassInfoWrapper-sc-1dlkqw1-1 jxOApy\"><div class=\"RatingHeader__StyledClass-sc-1dlkqw1-2 gxDIt\"><img src=\"/static/media/computer-icon.17c26169.svg\" alt=\"Computer Icon\" data-for=\"GLOBAL_TOOLTIP\" data-tip=\"Online Class\" data-tooltip=\"true\" class=\"OnlineCourseLogo__StyledLogo-qyf3kt-0 gemNec\" currentitem=\"false\"> CMSC131</div><div class=\"EmotionLabel__StyledEmotionLabel-sc-1u525uj-0 cJfJJi\"><span role=\"img\" aria-label=\"Sunglasses\">ðŸ˜Ž</span>awesome</div></div><div class=\"TimeStamp__StyledTimeStamp-sc-9q2r30-0 bXQmMr RatingHeader__RatingTimeStamp-sc-1dlkqw1-3 BlaCV\">Dec 3rd, 2020</div></div><div class=\"RatingValues__StyledRatingValues-sc-6dc747-0 bJSTHc\"><div class=\"RatingValues__RatingContainer-sc-6dc747-1 DObVa\"><div class=\"RatingValues__RatingLabel-sc-6dc747-2 gLxTSP\">Quality</div><div class=\"RatingValues__RatingValue-sc-6dc747-3 kLWEWI\">5.0</div></div><div class=\"RatingValues__RatingContainer-sc-6dc747-1 DObVa\"><div class=\"RatingValues__RatingLabel-sc-6dc747-2 gLxTSP\">Difficulty</div><div class=\"RatingValues__RatingValue-sc-6dc747-3 jILzuI\">1.0</div></div></div><div class=\"Rating__RatingInfo-sc-1rhvpxz-3 kEVEoU\"><div class=\"RatingHeader__StyledHeader-sc-1dlkqw1-0 fUEMJm\"><div class=\"RatingHeader__ClassInfoWrapper-sc-1dlkqw1-1 jxOApy\"><div class=\"RatingHeader__StyledClass-sc-1dlkqw1-2 gxDIt\"><img src=\"/static/media/computer-icon.17c26169.svg\" alt=\"Computer Icon\" data-for=\"GLOBAL_TOOLTIP\" data-tip=\"Online Class\" data-tooltip=\"true\" class=\"OnlineCourseLogo__StyledLogo-qyf3kt-0 gemNec\" currentitem=\"false\"> CMSC131</div><div class=\"EmotionLabel__StyledEmotionLabel-sc-1u525uj-0 cJfJJi\"><span role=\"img\" aria-label=\"Sunglasses\">ðŸ˜Ž</span>awesome</div></div><div class=\"TimeStamp__StyledTimeStamp-sc-9q2r30-0 bXQmMr RatingHeader__RatingTimeStamp-sc-1dlkqw1-3 BlaCV\">Dec 3rd, 2020</div></div><div class=\"CourseMeta__StyledCourseMeta-x344ms-0 fPJDHT\"><div class=\"MetaItem__StyledMetaItem-y0ixml-0 LXClX\">Would Take Again: <span>Yes</span></div><div class=\"MetaItem__StyledMetaItem-y0ixml-0 LXClX\">Grade: <span>A</span></div><div class=\"MetaItem__StyledMetaItem-y0ixml-0 LXClX\">Textbook: <span>No</span></div><div class=\"MetaItem__StyledMetaItem-y0ixml-0 LXClX\">Online Class: <span>Yes</span></div></div><div class=\"Comments__StyledComments-dzzyvm-0 gRjWel\">Fawzi is a legend</div><div class=\"RatingTags__StyledTags-sc-1boeqx2-0 eLpnFv\"><span class=\"Tag-bs9vf4-0 hHOVKF\">Hilarious</span><span class=\"Tag-bs9vf4-0 hHOVKF\">Lecture heavy</span></div><div class=\"RatingFooter__StyledRatingFooter-ciwspm-0 dbULCX\"><div class=\"RatingFooter__ButtonWrapper-ciwspm-1 cwcCIQ\"><div class=\"RatingFooter__HelpTotal-ciwspm-2 kAVFzA\"><img src=\"/static/media/thumbs-up-black.eddae738.svg\" class=\"VoteThumb__StyledVoteThumb-p2gtch-0 jCbELu\" data-tooltip=\"true\" data-tip=\"Helpful\" data-for=\"GLOBAL_TOOLTIP\" alt=\"Thumbs up\"> 0</div><div class=\"RatingFooter__HelpTotal-ciwspm-2 kAVFzA\"><img src=\"/static/media/thumbs-down-black.bd601b36.svg\" class=\"VoteThumb__StyledVoteThumb-p2gtch-0 jCbELu\" data-tooltip=\"true\" data-tip=\"Not helpful\" data-for=\"GLOBAL_TOOLTIP\" alt=\"Thumbs down\"> 0</div></div><div class=\"RatingFooter__ButtonWrapper-ciwspm-1 cwcCIQ\"><a href=\"https://www.ratemyprofessors.com//flagTeacherRating.jsp?rid=33939742\" class=\"ReportFlag__StyledReportFlag-sc-1c42epr-0 hjlYuE\" data-tooltip=\"true\" data-tip=\"Report this rating\" data-for=\"GLOBAL_TOOLTIP\" data-testid=\"reportflag_test_id\" aria-disabled=\"false\" currentitem=\"false\"><div class=\"ReportFlag__FlagWrapper-sc-1c42epr-1 kVglhF\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\"><defs><path id=\"prefix__a\" d=\"M3.93 10c1.417 0 2.383.276 4.371 1.072 1.762.704 2.546.928 3.629.928 1.189 0 2.094-.165 2.754-.428.095-.039.177-.075.246-.108v-9.86c-.82.253-1.814.396-3 .396-1.417 0-2.383-.276-4.371-1.072C5.797.224 5.013 0 3.93 0 2.741 0 1.836.165 1.176.428A4.094 4.094 0 00.93.536v9.86c.82-.253 1.814-.396 3-.396z\"></path></defs><g fill=\"none\" fill-rule=\"evenodd\"><path fill=\"#151515\" fill-rule=\"nonzero\" d=\"M3 3a1 1 0 01.293-.707c.22-.22.614-.483 1.21-.721C5.407 1.21 6.564 1 8 1c1.417 0 2.383.276 4.371 1.072C14.133 2.776 14.917 3 16 3c1.189 0 2.094-.165 2.754-.428.341-.137.508-.249.539-.28C19.923 1.663 21 2.11 21 3v12a1 1 0 01-.293.707c-.22.22-.614.483-1.21.721-.903.362-2.06.572-3.497.572-1.417 0-2.383-.276-4.371-1.072C9.867 15.224 9.083 15 8 15c-1.189 0-2.094.165-2.754.428a4.09 4.09 0 00-.247.108L5 22a1 1 0 01-2 0V3zm5 0c-1.189 0-2.094.165-2.754.428A4.094 4.094 0 005 3.536v9.86C5.82 13.143 6.814 13 8 13c1.417 0 2.383.276 4.371 1.072 1.762.704 2.546.928 3.629.928 1.189 0 2.094-.165 2.754-.428.095-.039.177-.075.246-.108v-9.86c-.82.253-1.814.396-3 .396-1.417 0-2.383-.276-4.371-1.072C9.867 3.224 9.083 3 8 3z\"></path><g transform=\"translate(4.07 3)\"><mask id=\"prefix__b\" fill=\"#fff\"><use xlink:href=\"#prefix__a\"></use></mask><use fill=\"none\" fill-rule=\"nonzero\" xlink:href=\"#prefix__a\"></use><g fill=\"none\" mask=\"url(#prefix__b)\"><path d=\"M0 0H64V64H0z\" transform=\"translate(-25 -27)\"></path></g></g></g></svg></div></a></div></div></div></div>\n",
    "\"\"\"\n",
    "\n",
    "print(parse_single_rmp_review(single_review, [\"CMSC131\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Management Professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Planetterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Science Professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Management Professors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
