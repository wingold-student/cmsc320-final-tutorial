{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Computer Science versus Business Management Introductory Course Professors Reviews and Their Trends Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "William Ingold, Erik Kelemen, Ashish Manda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project conducts a comprehensive analysis of the perceptions, grades, and reviews of computer science and business management undergraduate students at the University of Maryland, College Park. To achieve these means, we applied various data scraping, data processing, machine learning, and data visualization and analysis techniques we learned throughout the semester, and hope to demonstrate a deep understanding of data science techniques and the data science lifecycle. We also employed natural language processing and statistical analysis to draw conclusions and answer key questions. We will illustrate the major trends in student perception of core classes and professors (how favorable certain professors are, or how hard a class may be), and we will draw generalized conclusions about the trends we observe over time (is a major getting easier? more likable?). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was sparked by interest in a question that all undergraduate students, at one point or another, face: How do my peers experience the core courses that all prospective students in my major are required to take? We hope that, by aggregating and conducting analysis of reviews and data available on major course-review websites such as PlanetTerp and RateMyProfessor, we would be able to grasp a data informed perspective to answer this question. Erik, one of the group members, is also a dual degree undergraduate student, enrolled in both the Computer Science and Business schools at UMD, and was interested in comparing student perceptions between these two majors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Our GitHub Repository can be found here.](https://github.com/wingold-student/cmsc320-final-tutorial)\n",
    "\n",
    "Clone our repository for access to all the necessary drivers and databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Table of Contents](#Table-of-Contents)\n",
    "[Setup](#Setup) \n",
    "\n",
    "[Data Storage: Setup Storage for Reviews and Professors](#Data-Storage:-Setup-Databases-to-Hold-Review-Data)\n",
    "* [Part 1: Generic Database Functionality](#Data-Storage-Part-1:-Generic-Database-Functionality)\n",
    "* [Part 2: RateMyProfessor Functionality](#Data-Storage-Part-2:-RateMyProfessor-Specific-Database-Functionality)\n",
    "* [Part 3: PlanetTerp Functionality](#Data-Storage-Part-3:-PlanetTerp-Database-Functionality)\n",
    "\n",
    "[Data Collection: Getting Reviews and Professor Data](#Data-Collection-Part-1:-Grabbing-Introductory-Course-Professors-From-UMD.io)\n",
    "* [Part 1: Introductory Course Professors](#Data-Collection-Part-1:-Grabbing-Introductory-Course-Professors-From-UMD.io) \n",
    "* [Part 2: Scrape and Parse RateMyProfessor](#Data-Collection-Part-2:Grabbing-Reviews-From-RateMyProfessors)\n",
    "    * [CMSC RateMyProfessor Data](#Data-Collection-Part-2.8:-Scrape-and-Parse-All-Computer-Science-Professors-from-RateMyProfessor) - Actual data here\n",
    "    * [BMGT RateMyProfessor Data](#Data-Collection-Part-2.9:-Scrape-and-Parse-All-Business-Management-Professors-from-RateMyProfessor) - Actual data here\n",
    "* [Part 3: Query PlanetTerp API](#Data-Collection-Part-3:-Query-and-Parse-Data-from-PlanetTerp)\n",
    "    * [CMSC PlanetTerp Data](#Data-Collection-Part-3.4:-Parse-All-Computer-Science-Professors-from-PlanetTerp) - Actual data here\n",
    "    * [BMGT PlanetTerp Data](#Data-Collection-Part-3.5:-Parse-All-Business-Management-Professors-from-PlanetTerp) - Actual data here\n",
    "\n",
    "[Data Aggregation](#Data-Aggregation:-Putting-It-All-Together) - Actual data here\n",
    " \n",
    "[Analysis](#Analysis)\n",
    "\n",
    "[Analyzing Word Frequencies and Rudimentary Sentiment Analysis in Reviews](#Analyzing-Word-Frequencies-and-Rudimentary-Sentiment-Analysis-in-Reviews)\n",
    "\n",
    "[Insights and Conclusion](#Insights-and-Conclusion)\n",
    "\n",
    "[Potential Future Work](#Potential-Future-Work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Setup](#Setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technology Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Libraries\n",
    "* [Pandas](https://pandas.pydata.org/)\n",
    "* [Numpy](https://numpy.org/)\n",
    "* [Seaborn](https://seaborn.pydata.org/)\n",
    "* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [Selenium](https://www.selenium.dev/)\n",
    "* [SQLite3](https://docs.python.org/3/library/sqlite3.html#module-sqlite3)\n",
    "* [spaCy](https://spacy.io/) - With Conda use `conda install -c conda-forge spacy` to install\n",
    "* [Sci-Kit Learn](https://scikit-learn.org/stable/)\n",
    "\n",
    "Useful tools\n",
    "* [DB Browser for SQL](https://sqlitebrowser.org/) to view databases\n",
    "* [Postman](https://www.postman.com/downloads/) to interact with RESTful API's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RateMyProfessor requires JavaScript in order to parse the reviews of a professor.\n",
    "This is because the site utilizes a \"Load More\" button which is powered by\n",
    "JavaScript. To this end, we've utilized Selenium to load a browser and interact\n",
    "with RateMyProfessor for us, in order to 'click' the \"Load More\" button and scrape\n",
    "the appropriate review data.\n",
    "\n",
    "[Selenium](https://www.selenium.dev/) relies upon a local browser to operate. We have included drivers for\n",
    "Firefox v83.0 (x64), Microsoft Edge v87.0.664.60(x64), and Chrome v87.0.4280.88(x64). \n",
    "Here are the approriate file locations for them in our repository:\n",
    "* Firefox: `'./bin/geckodriver.exe'`\n",
    "* Edge: `'./bin/msedgedriver.exe'`\n",
    "* Chrome: `'./bin/chromedriver.exe'`\n",
    "\n",
    "For more information see the links below, especially if you need a different\n",
    "driver version or driver type:\n",
    "* https://selenium-python.readthedocs.io/installation.html\n",
    "* https://github.com/mozilla/geckodriver/releases/\n",
    "* https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/\n",
    "* https://chromedriver.chromium.org/downloads\n",
    "\n",
    "If you wish to rely purely on our databases, which have already scraped\n",
    "and parsed the data, you can simply set the following boolean \n",
    "should_scrape_rmp to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines if we should use Scrape RMP (won't rely upon database for data if True)\n",
    "should_scrape_rmp = False\n",
    "\n",
    "# Query PlanetTerp API (won't rely upon database for data if True)\n",
    "should_query_pt = False\n",
    "\n",
    "# Determines which Selenium driver to use\n",
    "use_firefox_driver = True\n",
    "use_chrome_driver  = False\n",
    "use_edge_driver    = False\n",
    "\n",
    "# Determine if we should utilize data storage\n",
    "should_store_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying and requests of pages\n",
    "import requests\n",
    "\n",
    "# Parsing and handling HTML elements\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Storage and manipulation of data\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import numpy as np\n",
    "\n",
    "# Used to check for the existance of files\n",
    "from os import path\n",
    "\n",
    "# Utilities\n",
    "import random\n",
    "from itertools import chain\n",
    "import collections\n",
    "import re\n",
    "import uuid # Used to make unique id's for reviews\n",
    "\n",
    "# Database and data storage\n",
    "import pickle\n",
    "import csv\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# Selenium lets us load pages more natively, and can interact with the page\n",
    "# NOTE: You must have Selenium downloaded in order to scrape RateMyProfessor\n",
    "# This means having Chrome, Firefox, or any other browser supported downloaded\n",
    "# and installed. It also requires a driver to be downloaded.\n",
    "# SEE: https://www.selenium.dev/documentation/en/selenium_installation/installing_webdriver_binaries/\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# For handling the time & dates for reviews\n",
    "import time\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "# Handling errors in try blocks\n",
    "import traceback\n",
    "\n",
    "# Graphs and Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "# Notebook Display and Utility\n",
    "from IPython.display import Image\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# SpaCy\n",
    "## If using conda, do conda install -c conda-forge spacy\n",
    "import spacy\n",
    "import string # for punctuation list\n",
    "\n",
    "# For ML and Statistics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Data Storage: Setup Databases to Hold Review Data](#Data-Storage:-Setup-Databases-to-Hold-Review-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created two separate database systems for RateMyProfessors and PlanetTerp accordingly to hold data scraped from both of these sites. Additionally, we have separated CMSC and BMGT data - so we have a total of 4 databases. We have generic database functionality such as checking if all the data has been scraped for a certain professor. We can also retrieve important characteristics including professor stats, reviews and course grades through pandas dataframes. In addition, based on these characteristics, we can also insert and retrieve review sentiments for each professor. In the RateMyProfessors database, we created tables to store data for professor statistics, reviews, review tags, and professor tags. In the PlanetTerp database, we created tables to store data for statistics, reviews, and grades.\n",
    "\n",
    "We used [SQLite3](https://www.sqlite.org/index.html) with Python for the storage. Since the data scraped from RateMyProfessor and PlanetTerp was relatively small, this offered a nice solution. Additionally, it made data storage easier to manage, since it was all local to our development. The separation was done preemptively to make the databases even more small and managable, along with just to keep a separation of data. However, choosing to only use one or two databases is perfectly fine as well, just not the route we opted for in this tutorial. Tutorials for SQLite in Python [can be found here](https://www.sqlitetutorial.net/sqlite-python/), if you want further information.\n",
    "\n",
    "We also recommend the use of [DB Browser for SQLite](https://sqlitebrowser.org/) for browsing the database data. This can be a more managable way to view the data, then simply printing out Pandas DataFrames. This was utilized rather often in this tutorial.\n",
    "\n",
    "If for some reason you do not wish to write or read from a database, the appropriate booleans are above to allow you to disable this. However, it is recommended you rely upon the databases, unless you want to scrape newer data or wish to experiment with the scraping, parsing and querying yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Storage Part 1: Generic Database Functionality](#Data-Storage-Part-1:-Generic-Database-Functionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section lays out generic database functionality, such as connecting to the database or executing SQL commands or queries. Additionally, it has functionality that works for all of our databases, regardless of it is for RateMyProfessor or PlanetTerp and for CMSC or BMGT. Functions that interact specifically RateMyProfessor and PlanetTerp are written in the following sections. We do this to keep functionality more separated and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup database presets\n",
    "db_filepath = './data/db/'\n",
    "bmgt_rmp_db_filepath = db_filepath + 'bmgt_rmp.db'\n",
    "cmsc_rmp_db_filepath = db_filepath + 'cmsc_rmp.db'\n",
    "\n",
    "bmgt_pt_db_filepath = db_filepath + 'bmgt_pt.db'\n",
    "cmsc_pt_db_filepath = db_filepath + 'cmsc_pt.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\"Create a connection to the provided database file.\n",
    "    \n",
    "    Args:\n",
    "        db_file: A string holding the filepath to a database.\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    \n",
    "    if should_store_data:\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_file)\n",
    "            return conn\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def execute_create_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    \n",
    "def execute_insert_command(conn, table_name, column_list, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Question mark for each value to be filled, don't want a trailing comma\n",
    "    question_marks = \"?,\" * (len(column_list) - 1)\n",
    "    question_marks = question_marks + \"?\"\n",
    "    \n",
    "    column_names = \",\".join(column_list)\n",
    "    \n",
    "    insert_sql = \"\"\"INSERT INTO {table_name} (\n",
    "                                {column_names}\n",
    "                           )\n",
    "                           VALUES({question_marks})\n",
    "                           \"\"\".format(table_name=table_name, \n",
    "                                      question_marks=question_marks,\n",
    "                                      column_names=column_names)\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(insert_sql, params)\n",
    "        conn.commit()\n",
    "        \n",
    "        return c.lastrowid\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "def execute_query_command(conn, sql_command, params=()):\n",
    "    \"\"\"Executes the provided sql_command on the provided database.\n",
    "    \n",
    "    Args:\n",
    "        conn: The connection object to the database.\n",
    "        sql_command: A string containing the SQL command.\n",
    "        params: A tuple of potential parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_command, params)\n",
    "        \n",
    "        return c.fetchall()\n",
    "    \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def is_professor_scraped(db_conn, professor_name):\n",
    "    \"\"\"Returns if the professor's RateMyProfessors page has been scraped already.\n",
    "    \n",
    "    Args:\n",
    "        db_conn: Connection object to the appropriate database.\n",
    "        professor_name: String holding the professor's name.\n",
    "    \"\"\"\n",
    "    \n",
    "    if should_store_data:\n",
    "        sql_command = \"\"\"SELECT\n",
    "                            full_name\n",
    "                        FROM\n",
    "                            professor_stats ps\n",
    "                        WHERE\n",
    "                            full_name LIKE ?\"\"\"\n",
    "\n",
    "        params=('%'+professor_name+'%',)\n",
    "\n",
    "        result = execute_query_command(db_conn, sql_command, params)\n",
    "\n",
    "        return len(result) != 0\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def insert_dataframe_into_db(db_conn, df, table_name, column_headers=None):\n",
    "    \"\"\"Inserts all rows of a given dataframe to the database's table.\n",
    "    \n",
    "    Args:\n",
    "        db_conn: Connection object to a database.\n",
    "        df: Pandas DataFrame object containing data to insert.\n",
    "        table_name: String holding a table name to insert into ('reviews' or 'professor_stats')\n",
    "    \"\"\"\n",
    "    \n",
    "    if should_store_data:\n",
    "        if column_headers is None:\n",
    "            column_list = list(df.columns)\n",
    "        else:\n",
    "            column_list = column_headers\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            execute_insert_command(db_conn, table_name, column_list, tuple(row.array))\n",
    "\n",
    "\n",
    "def get_professor_stats_from_db(db_conn, professor):\n",
    "    \"\"\"Reads the professor_stats table into a pandas dataframe and returns it.\"\"\"\n",
    "    \n",
    "    sql_query = \"\"\"SELECT * FROM professor_stats WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, db_conn, params=[professor])\n",
    "\n",
    "\n",
    "def get_professor_reviews_from_db(db_conn, professor):\n",
    "    \"\"\"Reads the reviews table into a pandas dataframe and returns it.\"\"\"\n",
    "    \n",
    "    sql_query = \"\"\"SELECT * FROM reviews WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, db_conn, params=[professor])\n",
    "\n",
    "\n",
    "def get_course_grades_from_db(db_conn, course):\n",
    "    \"\"\"Reads the grades table for a certain course into a pandas data\n",
    "    frame and returns it.\"\"\"\n",
    "    \n",
    "    if should_store_data:\n",
    "        sql_query = \"\"\"SELECT * FROM grades WHERE course LIKE ?\"\"\"\n",
    "\n",
    "        return pd.read_sql_query(sql_query, db_conn, params=[course])\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    \n",
    "def insert_review_sentiment(db_conn, review_id, sentiment_score, sentiment_label):\n",
    "    \"\"\"Inserts the sentiment score and ground label for a single review into the\n",
    "    database, specifically the reviews table. It does this by findining the \n",
    "    review id, which is a UUID. \n",
    "    \n",
    "    Args:\n",
    "        db_conn: A connection object to the database\n",
    "        review_id: A string holding the UUID for a single review.\n",
    "        sentiment_score: An integer that represents the sentiment score\n",
    "        sentiment_label: An integer that represents the sentiment (-1, 0, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    if should_store_data:\n",
    "        update_sql = \"\"\"UPDATE reviews\n",
    "                            SET sentiment_score = ?,\n",
    "                                sentiment_ground_label = ?\n",
    "                        WHERE review_id LIKE ?\"\"\"\n",
    "\n",
    "        try:\n",
    "            c = db_conn.cursor()\n",
    "            c.execute(update_sql, (sentiment_score, sentiment_label, review_id))\n",
    "            db_conn.commit()\n",
    "\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "        \n",
    "    \n",
    "def insert_all_review_sentiment_labels(db_conn, review_sentiment_df):\n",
    "    \"\"\"Takes a dataframe of reviews, sentiment labels and scores and inserts them into\n",
    "    a database.\"\"\"\n",
    "    \n",
    "    if should_store_data:\n",
    "        for row in review_sentiment_df.itertuples():\n",
    "            insert_review_sentiment(db_conn, row.review_id, row.sentiment_score, row.sentiment_ground_label)\n",
    "\n",
    "            \n",
    "def get_review_sentiment(db_conn, review_id):\n",
    "    \"\"\"Queries the database for the sentiment score gotten for a single review.\"\"\"\n",
    "    \n",
    "    sql_command = \"\"\"SELECT sentiment_score FROM reviews WHERE review_id LIKE ?\"\"\"\n",
    "    \n",
    "    result = execute_query_command(db_conn, sql_command, (review_id,))\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Storage Part 2: RateMyProfessor Specific Database Functionality](#Data-Storage-Part-2:-RateMyProfessor-Specific-Database-Functionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section only contains the functionality for database reading and writing for those that hold RateMyProfessor data. We opt, and suggest, you use a similar (if not same) structure for the database. It keeps the data separated nicely and keeps it tidy. We've opted for 6 tables in total. Professors can be referenced by their full name in the `professor_stats` and `professor_tags_table`, while a review's id can be used to reference data in the `reviews`, `review_tags` and the `meta_tags`. RateMyProfessor offers a lot of data, which wasn't used to its entirety in this tutorial. We've included this functionality purely for the potential use of it later - even by you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rmp_tables(rmp_conn):\n",
    "    \"\"\"Create the stats and review tables for RateMyProfessors data.\n",
    "    \n",
    "    Args:\n",
    "        rmp_conn: Connection object to a RateMyProfessors database.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_table = \"\"\" CREATE TABLE IF NOT EXISTS professor_stats (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        page_exists INTEGER NOT NULL,\n",
    "                        rating REAL,\n",
    "                        take_again REAL,\n",
    "                        difficulty REAL,\n",
    "                        rating_count INTEGER\n",
    "                    ) \"\"\"\n",
    "    \n",
    "    review_table = \"\"\" CREATE TABLE IF NOT EXISTS reviews (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        review_id TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        full_name TEXT NOT NULL,\n",
    "                        course TEXT NOT NULL,\n",
    "                        date INTEGER NOT NULL,\n",
    "                        body TEXT NOT NULL,\n",
    "                        thumb_up INTEGER,\n",
    "                        thumb_down INTEGER,\n",
    "                        rating REAL NOT NULL,\n",
    "                        difficulty REAL NOT NULL,\n",
    "                        sentiment_score REAL,\n",
    "                        sentiment_ground_label INTEGER\n",
    "                   ) \"\"\"\n",
    "    \n",
    "    review_tags_table = \"\"\"CREATE TABLE IF NOT EXISTS review_tags (\n",
    "                            id INTEGER PRIMARY KEY,\n",
    "                            review_id TEXT NOT NULL,\n",
    "                            tag_name TEXT NOT NULL\n",
    "                        )\"\"\"\n",
    "    \n",
    "    review_meta_table = \"\"\"CREATE TABLE IF NOT EXISTS meta_tags (\n",
    "                            id INTEGER PRIMARY KEY,\n",
    "                            review_id TEXT NOT NULL,\n",
    "                            meta_name TEXT NOT NULL,\n",
    "                            value TEXT NOT NULL\n",
    "                        )\"\"\"\n",
    "    \n",
    "    professor_tags_table = \"\"\"CREATE TABLE IF NOT EXISTS professor_tags (\n",
    "                                id INTEGER PRIMARY KEY,\n",
    "                                full_name TEXT NOT NULL,\n",
    "                                tag_name\n",
    "                        )\"\"\"\n",
    "    \n",
    "    execute_create_command(rmp_conn, stats_table)\n",
    "    execute_create_command(rmp_conn, review_table)\n",
    "    execute_create_command(rmp_conn, review_tags_table)\n",
    "    execute_create_command(rmp_conn, review_meta_table)\n",
    "    execute_create_command(rmp_conn, professor_tags_table)\n",
    "\n",
    "    \n",
    "def get_rmp_review_grade(rmp_conn, review_id):\n",
    "    sql_query = \"\"\"SELECT value, review_id FROM meta_tags WHERE review_id LIKE ? AND meta_name LIKE '%Grade%'\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[review_id])\n",
    "\n",
    "\n",
    "def get_rmp_review_tags(rmp_conn, review_id):\n",
    "    sql_query = \"\"\"SELECT review_id, tag_name FROM review_tags WHERE review_id LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[review_id])\n",
    "\n",
    "\n",
    "def get_rmp_review_all_meta(rmp_conn, review_id):\n",
    "    sql_query = \"\"\"SELECT review_id, meta_name, value FROM meta_tags WHERE review_id LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[review_id])\n",
    "\n",
    "\n",
    "def get_rmp_data_for_all_ids(rmp_filepath, review_df, query_func):\n",
    "    \"\"\"Given a DataFrame full of review_ids, query the database for the requested data\n",
    "    for each review_id and create a dataframe full of the data. This will be easier to\n",
    "    merge with other review dataframes, since they'll have matching review_ids.\n",
    "    \n",
    "    Args:\n",
    "        rmp_filepath: String holding the filepath to the RMP database.\n",
    "        review_df: A pandas dataframe that should hold review_ids\n",
    "        query_func: A RMP database query function, i.e. get_rmp_review_grade,\n",
    "            get_rmp_review_tags, get_rmp_all_meta\n",
    "            \n",
    "    Returns:\n",
    "        A dataframe with at least a review_id column and columns of requested data.\n",
    "    \"\"\"\n",
    "    \n",
    "    rmp_conn = create_connection(rmp_filepath)\n",
    "    data_df = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        data = review_df['review_id'].apply(lambda review_id: query_func(rmp_conn, review_id)).tolist()\n",
    "        data_df = pd.concat(data)\n",
    "    except Exception as e:\n",
    "        print(\"Type error: \" + str(e))\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        rmp_conn.close()\n",
    "        \n",
    "    return data_df \n",
    "\n",
    "\n",
    "def get_rmp_prof_tags(rmp_conn, full_name):\n",
    "    sql_query = \"\"\"SELECT tag_name FROM professor_tags WHERE full_name LIKE ?\"\"\"\n",
    "    \n",
    "    return pd.read_sql_query(sql_query, rmp_conn, params=[full_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're saving data (and we don't have the databases already) we'll create them and the tables.\n",
    "if should_store_data:\n",
    "    # Create the CMSC and BMGT database with the two tables\n",
    "    cmsc_rmp_db = create_connection(cmsc_rmp_db_filepath)\n",
    "    bmgt_rmp_db = create_connection(bmgt_rmp_db_filepath)\n",
    "\n",
    "    create_rmp_tables(cmsc_rmp_db)\n",
    "    create_rmp_tables(bmgt_rmp_db)\n",
    "\n",
    "    # Close for now, will reopen when writing to them\n",
    "    cmsc_rmp_db.close()\n",
    "    bmgt_rmp_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Storage Part 3: PlanetTerp Database Functionality](#Data-Storage-Part-3:-PlanetTerp-Database-Functionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create extra functionality for interacting with the PlanetTerp databases. Since PlanetTerp offers less data about reviews than RateMyProfessor, the structure and tables are simplified. The `professor_stats` and `reviews` table operate similar to the same table names in the RateMyProfessor databases. Both `professor_stats` share the use of the name of the professor, number of reviews, and overall rating. Similarly, both `reviews` tables have a review id, full name of the professor being rated, a date, course, body, and sentiment data. The `grades` table refers to data queried through the `https://api.planetterp.com/v1/grades` endpoint, which allows querying for the grade distribution per course. While likely similar to those reported for the grades reported by reviews, it never hurts to have extra data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pt_tables(pt_conn):\n",
    "    \"\"\"Create the stats and review tables for RateMyProfessors data.\n",
    "    \n",
    "    Args:\n",
    "        pt_conn: Connection object to a PlanetTerp database.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_table = \"\"\" CREATE TABLE IF NOT EXISTS professor_stats (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        first_name TEXT NOT NULL,\n",
    "                        last_name TEXT NOT NULL,\n",
    "                        full_name TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        page_exists INTEGER NOT NULL,\n",
    "                        slug TEXT,\n",
    "                        review_count INTEGER NOT NULL,\n",
    "                        rating REAL,\n",
    "                        type TEXT\n",
    "                    ) \"\"\"\n",
    "    \n",
    "    review_table = \"\"\" CREATE TABLE IF NOT EXISTS reviews (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        review_id TEXT NOT NULL UNIQUE ON CONFLICT IGNORE,\n",
    "                        full_name TEXT NOT NULL,\n",
    "                        course TEXT NOT NULL,\n",
    "                        date INTEGER NOT NULL,\n",
    "                        body TEXT NOT NULL,\n",
    "                        rating INTEGER NOT NULL,\n",
    "                        expected_grade TEXT,\n",
    "                        sentiment_score REAL,\n",
    "                        sentiment_ground_label INTEGER\n",
    "                   ) \"\"\"\n",
    "    \n",
    "    grades_table = \"\"\" CREATE TABLE IF NOT EXISTS grades (\n",
    "                            id INTEGER PRIMARY KEY,\n",
    "                            course TEXT NOT NULL,\n",
    "                            semester INTEGER,\n",
    "                            grade TEXT,\n",
    "                            count INTEGER NOT NULL\n",
    "                    )\"\"\"\n",
    "    \n",
    "    execute_create_command(pt_conn, stats_table)\n",
    "    execute_create_command(pt_conn, review_table)\n",
    "    execute_create_command(pt_conn, grades_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_store_data:\n",
    "    # Create the CMSC and BMGT database with the two tables\n",
    "    cmsc_pt_db = create_connection(cmsc_pt_db_filepath)\n",
    "    bmgt_pt_db = create_connection(bmgt_pt_db_filepath)\n",
    "\n",
    "    create_pt_tables(cmsc_pt_db)\n",
    "    create_pt_tables(bmgt_pt_db)\n",
    "\n",
    "    # Close for now, will reopen when writing to them\n",
    "    cmsc_pt_db.close()\n",
    "    bmgt_pt_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this section, we've created functionality to create databases, insert data from both RateMyProfessor and PlanetTerp, and query for data from the databases. Again, while we feel our database structure was the best layout, others would do as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Data Collection Part 1: Grabbing Introductory Course Professors From UMD.io](#Data-Collection-Part-1:-Grabbing-Introductory-Course-Professors-From-UMD.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API documentation for [UMD.io is here](https://beta.umd.io/) and [PlanetTerp is here](https://api.planetterp.com/#planetterp-api).\n",
    "\n",
    "We utilize the APIâ€™s from both UMD.io and PlanetTerp to collect data regarding the professors and courses they offer. Since we are analyzing the trends in introductory courses, we are collecting statistics for the CS intro courses CMSC131, CMSC132, CMSC216, and CMSC250. Meanwhile, on the business side, we are collecting data for intro courses BMGT110, BMGT220, BMGT221, and BMGT230. We start by grabbing a general list of professors and the courses they offer at UMD. Then, we are able to map each professor to the introductory courses mentioned above that they offer by creating a dictionary of professor to courses. Lastly, we can separate the professors into their specific department to create a list of CMSC and BMGT professors.\n",
    "\n",
    "We query both UMD.io and PlanetTerp because while they should share the same data, they don't seem to be the exact same. So, both were queried in order to ensure we got all the data we could. Meaning, we got as many professors who have taught these courses as possible. They were stored as dictionaries of `{ professor : [courses] }` taught. Readubg and writing of this data was done through [Python's DictReader and DictWriter](https://docs.python.org/3/library/csv.html). While the course list is not utilized in this tutorial, we figured it could be applicable later or for different analysis. Again, sometimes a professor taught more courses than reported from UMD.io and PlanetTerp.\n",
    "\n",
    "Introductory courses for [CMSC were found here](https://undergrad.cs.umd.edu/degree-requirements-cs-major) and introductory courses for [BMGT were found here](https://www.rhsmith.umd.edu/files/Documents/Programs/Undergraduate/Management/mgmt2017.pdf). You can change this courses or majors you please (although we have stuck with a naming convention to only use CMSC and BMGT courses). To reiterate our introduction, we chose these courses because we felt they gave the best insight into the major for students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base API url for UMD.io\n",
    "professors_url = \"https://api.umd.io/v1/professors\"\n",
    "\n",
    "# Base API url for PlanetTerp\n",
    "pt_courses_url = \"https://api.planetterp.com/v1/course\"\n",
    "\n",
    "# The filepaths for the files to hold professor information\n",
    "cmsc_professor_names_filepath = './data/cmsc_professor_names.csv'\n",
    "bmgt_professor_names_filepath = './data/bmgt_professor_names.csv'\n",
    "\n",
    "# Determines if we've created these already\n",
    "have_cmsc_professors = path.exists(cmsc_professor_names_filepath)\n",
    "have_bmgt_professors = path.exists(bmgt_professor_names_filepath)\n",
    "\n",
    "# The courses we've chosen to look at in reviews\n",
    "cmsc_course_ids = [\"CMSC131\", \"CMSC132\", \"CMSC216\", \"CMSC250\"]\n",
    "bmgt_course_ids = [\"BMGT110\", \"BMGT220\", \"BMGT221\", \"BMGT230\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for saving and reading professor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_professor_name_data(professor_filepath):\n",
    "    \"\"\"Reads the professor names and their courses from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professor_filepath: String holding a filepath to the professor csv file.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of professor names to a set of courses they have taught.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(professor_filepath, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "\n",
    "        professors = {}\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if line_count != 0:\n",
    "                professors[row['name']] = set([course for course in row['courses'].split(' ')])\n",
    "            line_count += 1\n",
    "\n",
    "        return professors\n",
    "\n",
    "    \n",
    "def save_professor_data(professors, filepath):\n",
    "    \"\"\"Saves the professor names and their courses to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        professors: A dictionary of professor name keys and a set of courses for values.\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = ['name', 'courses']\n",
    "    try:\n",
    "        with open(filepath, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for name, courses in professors.items():\n",
    "                writer.writerow({'name': name, 'courses': ' '.join(courses)})\n",
    "                \n",
    "    except IOError:\n",
    "        print(\"Error in writing the CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility to actually grab professors based on a list of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_professors_for_courses_from_umdio(course_ids):\n",
    "    \"\"\"Gets all the professors for the given course_ids from UMD.io \n",
    "    and returns a dictionary of professor to courses.\n",
    "    \n",
    "    Args:\n",
    "        course_ids: A list of course ids (e.g. ['CMSC216', CMSC250']).\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of professor to set of courses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    professors = {}\n",
    "    \n",
    "    for course_id in course_ids:\n",
    "        params = {'course_id': course_id}\n",
    "\n",
    "        response = requests.get(professors_url, params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "\n",
    "            for item in response.json():\n",
    "                name = item['name']\n",
    "\n",
    "                if name in professors:\n",
    "                    professors[name].add(course_id)\n",
    "                else:\n",
    "                    professors[name] = {course_id}\n",
    "\n",
    "    return professors\n",
    "\n",
    "\n",
    "def get_professors_for_courses_from_pt(course_ids):\n",
    "    \"\"\"Gets all the professors for the given course_ids from PlanetTerp\n",
    "    and returns a dictionary of professor to courses.\n",
    "    \n",
    "    Args:\n",
    "        course_ids: A list of course ids (e.g. ['CMSC216', CMSC250']).\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of professor to set of courses.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    professor_list = {}\n",
    "    \n",
    "    for course_id in course_ids:\n",
    "        params = {'name': course_id}\n",
    "\n",
    "        response = requests.get(pt_courses_url, params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            professors = response.json().get('professors', None)\n",
    "            \n",
    "            if professors:\n",
    "                for professor in professors:\n",
    "                    if professor in professor_list:\n",
    "                        professor_list[professor].add(course_id)\n",
    "                    else:\n",
    "                        professor_list[professor] = {course_id}\n",
    "\n",
    "    return professor_list\n",
    "\n",
    "\n",
    "def combine_professor_dictionaries(dict_one, dict_two):\n",
    "    \"\"\"Combines two dictionaries of professor data into a single dictionary.\"\"\"\n",
    "    \n",
    "    combined_profs = collections.defaultdict(set)\n",
    "\n",
    "    for key, val in chain(dict_one.items(), dict_two.items()):\n",
    "        combined_profs[key] = combined_profs[key].union(val)\n",
    "        \n",
    "    return combined_profs\n",
    "\n",
    "\n",
    "def get_all_professors_from_courses(course_ids):\n",
    "    \"\"\"Queries both UMD.io and PlanetTerp for the professors who have\n",
    "    taught the provided course_ids and combines the data into a single\n",
    "    dictionary, which is returned.\"\"\"\n",
    "    \n",
    "    umdio_professors = get_professors_for_courses_from_umdio(course_ids)\n",
    "    pt_professors = get_professors_for_courses_from_pt(course_ids)\n",
    "    \n",
    "    return combine_professor_dictionaries(umdio_professors, pt_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Computer Science Professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual** work! Here we query UMD.io and PlanetTerp for the **CMSC** professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only query the UMD.io API if we don't have the data\n",
    "if not have_cmsc_professors or not should_store_data:\n",
    "    cmsc_professors = get_all_professors_from_courses(cmsc_course_ids)\n",
    "    \n",
    "    save_professor_data(cmsc_professors, cmsc_professor_names_filepath)\n",
    "    have_cmsc_professors = True\n",
    "else: \n",
    "    cmsc_professors = read_professor_name_data(cmsc_professor_names_filepath)\n",
    "\n",
    "    if not cmsc_professors:\n",
    "        print(\"Error response from umd.io API\")\n",
    "\n",
    "if 'Iason Filippou' in cmsc_professors:\n",
    "    cmsc_professors.pop('Iason Filippou') # A typo of Jason Filippou from the database\n",
    "    \n",
    "print(cmsc_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Business Management Professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual** work! Here we query UMD.io and PlanetTerp for the **BMGT** professors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only query the UMD.io API if we don't have the data\n",
    "if not have_bmgt_professors or not should_store_data:\n",
    "    bmgt_professors = get_all_professors_from_courses(bmgt_course_ids)\n",
    "    \n",
    "    save_professor_data(bmgt_professors, bmgt_professor_names_filepath)\n",
    "    have_bmgt_professors = True\n",
    "else:\n",
    "    bmgt_professors = read_professor_name_data(bmgt_professor_names_filepath)\n",
    "\n",
    "    if not bmgt_professors:\n",
    "        print(\"Error response from umd.io API\")\n",
    "\n",
    "print(bmgt_professors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Data Collection Part 2: Grabbing Reviews From RateMyProfessors](#Data-Collection-Part-2:Grabbing-Reviews-From-RateMyProfessors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is all about getting stats on professors and reviews of them with [RateMyProfessor, a well known website for reviewing professors and schools](https://www.ratemyprofessors.com/). However, RateMyProfessor does **not** offer an API to query for their reviews as a JSON. Therefore, the website must be scraped manually. \n",
    "Searching relies upon a few parameters:\n",
    "* queryoption - This seems to be some default parameter used when searching\n",
    "* schoolID - A number representing the school, (1270 is University of Maryland's ID)\n",
    "* queryBy - Determines how to query, either by school or professor name. We used 'teacherName'\n",
    "* schoolName - The name of the school to search professors for in (We used 'University of Maryland')\n",
    "\n",
    "An example query URL you'd find if you went to search RateMyProfessor yourself:\n",
    "https://www.ratemyprofessors.com/search.jsp?queryoption=HEADER&queryBy=teacherName&schoolName=University+of+Maryland&schoolID=1270&query=Mohammad+Nayeem+Teli\n",
    "\n",
    "After querying this URL, we will get a list of potential professors (which should only be about 1 or 2, depending on if the professor has taught in different colleges at the school). Then we obtain the URL of the professor's page in order to parse their overall information such as their corresponding statistics and tags.\n",
    "\n",
    "With the professor's URL, we break down parsing and scraping into two sections: \n",
    "First, the professor statistics. This includes their name, overall rating, number of ratings, percetange of who would take again, and the average level of difficulty reported. \n",
    "This data goes into the `professor_stats` table. The professor tags are also parsed and placed into the `professor_tags` table. Scraping of this data is all achievable with only the `requests` python library and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library. \n",
    "\n",
    "Second, the professor's reviews. We utilize the [Selenium browser](https://selenium-python.readthedocs.io/) to load all the professor reviews which are continuously loaded since RateMyProfessors paginates the reviews via Javascript. Once all reviews are loaded, the HTML data for the list of reviews is scraped, then handed off for parsing by BeautifulSoup. For each review, we parse every part of the review including ratings, tags, thumb scoring, etc. The review's text, rating, difficulty, course, thumb scoring, post date, and professor name are all saved into the `reviews` table. Review meta tags, such as `Online Class: Yes` or `Grade: A` are stored in `meta_tags`. The review's tags used to describe the professor are stored in the `review_tags` table.\n",
    "\n",
    "Professor statistics and reviews are filtered by their respective major, thus we have separate CMSC and BMGT databases for RateMyProfessor data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 2.1: Setup and Utilities to Scrape and Parse Data from RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data needed for requesting data from RateMyProfessor\n",
    "ratemyprofessor_url = \"https://www.ratemyprofessors.com/search.jsp\"\n",
    "params = {'queryoption':'HEADER', 'schoolID':'1270', 'queryBy':'teacherName', 'schoolName':'University+of+Maryland'}\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\",\n",
    "    \"Access-Control-Allow-Origin\": \"*\",\n",
    "    \"Access-Control-Allow-Headers\": \"Content-Type\",\n",
    "    \"Access-Control-Allow-Methods\": \"GET\",\n",
    "}\n",
    "\n",
    "# These are the column headers for a professor's overall statistics found at the top of the page\n",
    "overall_header_list = ['first_name', 'last_name', 'full_name', 'page_exists', 'rating', 'take_again', 'difficulty',\n",
    "                      'rating_count']\n",
    "\n",
    "# Review post column headers. The meta list is the row of top meta responses (like 'Grade: A-').\n",
    "review_header_list = ['review_id', 'full_name', 'course', 'date', 'rating', 'difficulty', 'body',\n",
    "                      'thumb_up', 'thumb_down']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 2.2: Querying RateMyProfessor and Getting the Professor's URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RateMyProfessor Example Search](img/RMP_Search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in this sections introduction, we must find the professor's actual RateMyProfessor URL after a search. If you were to search in your browser you'd be faced with the above photo. The professor's link is their name within the list item, which is surrounded by the red box (added for emphasis). Using BeautifulSoup, we search for the list item, then for the link tag within to scrape the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rmp_professor_url(html_doc):\n",
    "    \"\"\"Finds the professor's URL on the search page and returns it.\n",
    "    \n",
    "    Args:\n",
    "        html_doc: A string containing an HTML document.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page (if found).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    main_url = \"https://www.ratemyprofessors.com\"\n",
    "    prof_urls = []\n",
    "    \n",
    "    no_results = soup.find('div[class*=\"NoResultsFoundArea__StyledNoResultsFound\"]')\n",
    "    prof_list_items = soup.find_all('li', class_='listing PROFESSOR')\n",
    "    \n",
    "    # Sometimes RMP does the search differntly, so it'll be elsewhere\n",
    "    diff_location = soup.find('a', attrs={'class': lambda x: 'TeacherCard__StyledTeacherCard' in x if x else False}, href=True)\n",
    "    \n",
    "    # The professor may not be reviewed\n",
    "    if no_results is None and prof_list_items and len(prof_list_items) != 0:\n",
    "        if diff_location:\n",
    "            prof_urls.append(main_url + diff_location['href'])\n",
    "        else:\n",
    "            # Each should be from University of Maryland due to search params\n",
    "            for item in prof_list_items: \n",
    "                partial_url = item.find('a', href=True)\n",
    "\n",
    "                if partial_url:\n",
    "                    prof_urls.append(main_url + partial_url['href'])\n",
    "                        \n",
    "                        \n",
    "    return prof_urls\n",
    "    \n",
    "    \n",
    "def query_rmp_for_professor_url(professor_name, headers, params):\n",
    "    \"\"\"Queries RateMyProfessor for the professor, given the parameters and headers.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: The <first name> <last name> of the professor.\n",
    "        headers: Dictionary of headers for the get request.\n",
    "        params: Dictionary of parameters for the get request.\n",
    "        \n",
    "    Returns:\n",
    "        The full URL for the professor's page after searching for it (if found).\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    params['query'] = professor_name\n",
    "    \n",
    "    response = requests.get(ratemyprofessor_url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        url = find_rmp_professor_url(response.text)\n",
    "        \n",
    "        if url is not None:\n",
    "            return url\n",
    "        else:\n",
    "            print(\"Professor {name} has not been reviewed.\".format(name=professor_name))\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 2.3: Parsing the Professor Overall Information (Stats and Tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RateMyProfessor Professor Stats](img/RMP_Stats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we need to scrape all the professor's statistics from their RateMyProfessor page. This includes their overall rating, amount of reviews, how many would take the professor again, their average level of difficulty. This data is placed into the `professor_stats` table later. Additionally, the `Top Tags` such as `Amazing Lectures` are scraped. Their tags are placed in the `professor_tags` table later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_stats(page_text):\n",
    "    \"\"\"Parses the professor's stats from their page and returns them. Namely their overall rating, \n",
    "    how many would take again, overall difficulty and how many ratings they have on RateMyProfessor.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing their rating, take again percentage, difficulty rating, and rating count.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    rating_score = soup.select('div[class*=\"RatingValue__Numerator\"]')\n",
    "    \n",
    "    # Some professors may not have these stats, so we establish NaN by default\n",
    "    take_again = np.nan\n",
    "    difficulty = np.nan\n",
    "    \n",
    "    # Some professors will have no reviews, but still have a page. This'll result in a N/A review score.\n",
    "    if rating_score is not None and rating_score[0].text != 'N/A':\n",
    "        rating_score = float(rating_score[0].text)\n",
    "    else:\n",
    "        rating_score = np.nan\n",
    "    \n",
    "    # The take again and difficulty data are within this div container\n",
    "    feedback_cont = soup.select('div[class*=\"TeacherFeedback__StyledTeacherFeedback\"]') \n",
    "    \n",
    "    # Want to check this container exists\n",
    "    if feedback_cont and len(feedback_cont) > 0:\n",
    "        \n",
    "        # Both take again and difficulty are surrounded in their own div container of this class\n",
    "        feedback_nums = feedback_cont[0].select('div[class*=\"FeedbackItem__FeedbackNumber\"]')\n",
    "        \n",
    "        # Only get data if they exist on the page\n",
    "        if feedback_nums and len(feedback_nums) == 2:\n",
    "            if len(feedback_nums[0].text) > 0:\n",
    "                try:\n",
    "                    take_again = float(feedback_nums[0].text[:-1]) / 100\n",
    "                except ValueError:\n",
    "                    take_again = np.nan\n",
    "                \n",
    "            if len(feedback_nums[1].text) > 0:\n",
    "                try:\n",
    "                    difficulty = float(feedback_nums[1].text)\n",
    "                except ValueError:\n",
    "                    difficulty = np.nan\n",
    "    \n",
    "    # Not all professors have reviews, so they'll have no count\n",
    "    rating_count_int = 0\n",
    "    rating_count_cont = soup.select('div[class*=\"RatingValue__NumRatings\"]') #[0].select('a')[0].text\n",
    "    \n",
    "    # Check this container exists\n",
    "    if rating_count_cont and len(rating_count_cont) > 0:\n",
    "        rating_count_a = rating_count_cont[0].select('a')\n",
    "        \n",
    "        # The rating count is a link, so we extract the text from it (if it exists)\n",
    "        if rating_count_a and len(rating_count_a) > 0:\n",
    "            rating_count = rating_count_a[0].text\n",
    "            \n",
    "            try:\n",
    "                rating_count_int = int(rating_count)\n",
    "            except ValueError:\n",
    "                rating_count_int = 0\n",
    "            \n",
    "        \n",
    "    # TODO: Necessary anymore?\n",
    "    try:\n",
    "        rating_count_int = int(''.join([x for x in rating_count if x.isdigit()]))\n",
    "    except ValueError:\n",
    "        rating_count_int = 0\n",
    "        \n",
    "    stats_dict = {'rating': rating_score, 'take_again': take_again, 'difficulty': difficulty, 'rating_count': rating_count_int}\n",
    "    return stats_dict\n",
    "\n",
    "\n",
    "def get_rmp_prof_top_tags(page_text, prof_name, rmp_conn):\n",
    "    \"\"\"Parses and returns the professor's top tags.\n",
    "    \n",
    "    Args:\n",
    "        page_text: An HTML document of the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tags describing the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "    tags_df = pd.DataFrame(columns=['full_name', 'tag_name'])\n",
    "    \n",
    "    # Tags are found in this div container\n",
    "    unparsed_tags = soup.select('div[class*=\"TeacherTags__TagsContainer\"]')\n",
    "    \n",
    "    # Check the container exists (since some professors don't have tags)\n",
    "    if unparsed_tags and len(unparsed_tags) != 0:\n",
    "        unparsed_tags = unparsed_tags[0].select('span')\n",
    "    \n",
    "        # We want a 'row' per tag associated with the professor, to keep data tidy\n",
    "        for tag in unparsed_tags:\n",
    "            tags_df = tags_df.append({'full_name': prof_name, 'tag_name': tag.text}, ignore_index=True)\n",
    "        \n",
    "    # Saves the data to the databases\n",
    "    insert_dataframe_into_db(rmp_conn, tags_df, 'professor_tags')\n",
    "\n",
    "\n",
    "def rmp_prof_overall_to_dataframe(professor_name, stats, page_exists=1):\n",
    "    \"\"\"Combines the professor's overall stats and tags into a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "        professor_name: String holding the professor's name.\n",
    "        stats: A dictionary holding the overall stats (e.g. 'would_take_again': .83).\n",
    "        tags: A dictionary holding the tags associated with a professor (e.g. {'caring': 1}).\n",
    "        page_exists (optional, default=1): Integer boolean determining if a professor has a RMP page.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing the combination of professor name, stats, and tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    overall_df = pd.DataFrame(columns=overall_header_list)\n",
    "    \n",
    "    # Add the professor's name data\n",
    "    first_name, last_name = professor_name.split(' ', 1)\n",
    "    overall_dict = {'first_name': first_name, 'last_name': last_name, 'full_name': professor_name, 'page_exists': page_exists}\n",
    "    \n",
    "    # Put in the professor statistics, along with the name data into the dataframe\n",
    "    overall_dict.update(stats)\n",
    "    overall_df = overall_df.append(overall_dict, ignore_index=True)\n",
    "    \n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 2.4: Use Selenium to Load All Professor Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Load More Button](img/RMP_Load_More.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated earlier, RateMyProfessor utilizes pagination of their reviews via JavaScript and the `Load More Ratings` button. BeautifulSoup cannot interact with JavaScript, so we must rely upon Selenium to load the page for us and click the button as long as it is present. This will assure us that the entire list of reviews has been loaded for the professor. Without we'd only get the most recent reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_selenium():\n",
    "    \"\"\"Starts up the Selenium browser.\"\"\"\n",
    "    \n",
    "    if use_edge_driver:\n",
    "        path = './bin/msedgedriver.exe'\n",
    "        driver = webdriver.Edge(executable_path=path)\n",
    "        \n",
    "    elif use_chrome_driver:\n",
    "        path = './bin/chromedriver.exe'\n",
    "        driver = webdriver.Chrome(path)\n",
    "        \n",
    "    else:\n",
    "        path = './bin/geckodriver.exe'\n",
    "        driver = webdriver.Firefox(executable_path=path)\n",
    "        \n",
    "    return driver\n",
    "    \n",
    "    \n",
    "def stop_selenium(driver):\n",
    "    \"\"\"Shutdown the Selenium browser.\"\"\"\n",
    "    \n",
    "    driver.close()\n",
    "    driver.quit()\n",
    "    \n",
    "    \n",
    "def load_all_rmp_reviews(page_url, driver):\n",
    "    \"\"\"Loads all the reviews for a given porfessor and returns the text of all of them.\n",
    "    \n",
    "    Args:\n",
    "        page_url: The URL for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the HTML for all the reviews.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open up the page with Selenium\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # RateMyProfessors has a cookies pop up that overlays the website, it needs to be closed first\n",
    "    time.sleep(1)\n",
    "    close_cookies = driver.find_elements(By.XPATH, '//button[text()=\"Close\"]')\n",
    "    \n",
    "    if close_cookies:\n",
    "        close_cookies[0].click()\n",
    "        \n",
    "    # Look for the Load More Ratings button\n",
    "    load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "    \n",
    "    # RateMyProfessors paginates the reviews via Javascript, so we must continually load more while the button is present\n",
    "    while load_more:\n",
    "        load_more[0].click()\n",
    "        time.sleep(1)\n",
    "        load_more = driver.find_elements(By.XPATH, '//button[text()=\"Load More Ratings\"]')\n",
    "        \n",
    "        \n",
    "    # Not all professors have reviews, so we check first. But we take the entire HTML element\n",
    "    # Of the ratings list and return it.\n",
    "    try:\n",
    "        all_reviews = driver.find_element_by_id('ratingsList').get_attribute('outerHTML')\n",
    "    except NoSuchElementException:\n",
    "        all_reviews = ''\n",
    "    \n",
    "    \n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 2.5: Parsing Utilities for a Single Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RateMyProfessor Review Example](img/RMP_Review.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RateMyProfessor reviews are **packed** with data! The top row has data about the course name and date, see `parse_rating_header` for how it is parsed. The second row, from `For Credit: Yes` to `Textbook: No`, are referred to meta tags that describe the course for the student (see `parse_meta_data`). The `Quality` and `Difficulty` ratings describe the student's experience of the professor and course, and are parsed in `parse_rating_data`. Each reviewer has the option of attaching tags that describe the professor and course, such as `Gives good feedback` in the image. The review tags are parsed with `parse_review_tags`. Reviews can be liked or disliked via the thumbs up and down. This data is parsed with `parse_thumb_scoring`. **Finally**, the review body is parsed through `parse_review_text`. All of this is wrapped up in the `parse_single_review` to maintain readibility.\n",
    "\n",
    "Admittedly, this is a lot of data per review. Do not feel obligated to parse all of this data alike us. However, we did so you don't have to! This data is held within the databases in the GitHub repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_date_to_unix(date_str):\n",
    "    \"\"\"Turns the RateMyProfessor date format (e.g. Nov 23rd, 2020) into a\n",
    "    UTC timestamp. Assumes the date is already in UTC.\n",
    "    \n",
    "    Args:\n",
    "        date_str: A string containing the RateMyProfessor review date.\n",
    "        \n",
    "    Returns:\n",
    "        A UTC timestamp corresponding to the date provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split into month, day, year\n",
    "    date_split = date_str.split(' ')\n",
    "    day = date_split[1]\n",
    "    \n",
    "    # Remove comma and suffix for day\n",
    "    day = day[:-3]\n",
    "    \n",
    "    # Place the day back into the list and join everything back together\n",
    "    date_split[1] = day\n",
    "    remade_date_str = (' ').join(date_split)\n",
    "    \n",
    "    # Change into UTC time\n",
    "    datetime_obj = datetime.datetime.strptime(remade_date_str, '%b %d %Y')\n",
    "    utc_time = datetime_obj.timestamp()\n",
    "    \n",
    "    return utc_time\n",
    "    \n",
    "    \n",
    "def parse_rating_header(soup):\n",
    "    \"\"\"Parses and returns the rating header for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the course and date for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_header = soup.select('div[class*=\"Rating__RatingInfo\"]')\n",
    "    \n",
    "    if len(rating_header) != 0:\n",
    "        course = rating_header[0].select('div[class*=\"RatingHeader__StyledClass\"]')[0].text.strip()\n",
    "        date = rating_header[0].select('div[class*=\"TimeStamp__StyledTimeStamp\"]')[0].text.strip()\n",
    "        \n",
    "        utc_time = string_date_to_unix(date)\n",
    "    else:\n",
    "        print(soup)\n",
    "    \n",
    "    return {'course': course, 'date': utc_time}\n",
    "\n",
    "\n",
    "def parse_meta_data(soup, review_id, rmp_conn):\n",
    "    \"\"\"Parses and returns the meta data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data (e.g. Would Take Again) for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    course_meta = soup.select('div[class*=\"CourseMeta__StyledCourseMeta\"]')[0]\n",
    "    review_meta_data = {}\n",
    "    \n",
    "    meta_tag_df = pd.DataFrame(columns=['review_id', 'meta_name', 'value'])\n",
    "\n",
    "    for meta_div in course_meta.select('div'):\n",
    "        meta_data = meta_div.text.split(':')\n",
    "        meta_name = meta_data[0].strip()\n",
    "        meta_value = meta_data[1].strip()\n",
    "\n",
    "        meta_tag_df = meta_tag_df.append({'review_id': review_id, 'meta_name': meta_name, 'value': meta_value}, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    insert_dataframe_into_db(rmp_conn, meta_tag_df, 'meta_tags')\n",
    "\n",
    "\n",
    "def parse_rating_data(soup):\n",
    "    \"\"\"Parses and returns the rating data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the rating data for the quality and difficulty for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_values_text = soup.select('div[class*=\"RatingValues__StyledRatingValues\"]')[0].select('div[class*=\"RatingValues__RatingValue\"]')\n",
    "    quality = rating_values_text[0].text\n",
    "    difficulty = rating_values_text[1].text\n",
    "\n",
    "    rating_data = {'rating': quality, 'difficulty': difficulty}\n",
    "    \n",
    "    return rating_data\n",
    "\n",
    "\n",
    "def parse_review_tags(soup, review_id, rmp_conn):\n",
    "    \"\"\"Parses and returns the tags for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A list containing the tags for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_container = soup.select('div[class*=\"RatingTags__StyledTags\"]')\n",
    "    \n",
    "    review_tags_df = pd.DataFrame(columns=['review_id', 'tag_name'])\n",
    "    \n",
    "    if tag_container: # Since not all reviews add tags\n",
    "        unparsed_tags = tag_container[0].select('span')\n",
    "\n",
    "        for tag in unparsed_tags:\n",
    "            review_tags_df = review_tags_df.append({'review_id': review_id, 'tag_name': tag.text}, ignore_index=True)\n",
    "\n",
    "    insert_dataframe_into_db(rmp_conn, review_tags_df, 'review_tags')\n",
    "    \n",
    "    \n",
    "def parse_thumb_scoring(soup):\n",
    "    \"\"\"Parses and returns the thumb scoring data for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the thumb scoring data for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    thumb_container = soup.select('div[class*=\"RatingFooter__StyledRatingFooter\"]')[0].select('div[class*=\"RatingFooter__HelpTotal\"]')\n",
    "\n",
    "    thumb_up = int(thumb_container[0].text.strip())\n",
    "    thumb_down = int(thumb_container[1].text.strip())\n",
    "    thumb_data = {'thumb_up': thumb_up, 'thumb_down': thumb_down}\n",
    "\n",
    "    return thumb_data\n",
    "\n",
    "\n",
    "def parse_review_text(soup):\n",
    "    \"\"\"Parses and returns the review body text for a single review.\n",
    "    \n",
    "    Args:\n",
    "        soup: An initialized BeautifulSoup object for the professor's page.\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the review text for the review.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_text = soup.select('div[class*=\"Comments__StyledComments\"]')[0].text\n",
    "    \n",
    "    return {'body': review_text}\n",
    "    \n",
    "    \n",
    "def parse_single_rmp_review(rmp_url, review_item, courses, rmp_conn):\n",
    "    \"\"\"Parses and returns all data for a single review.\n",
    "    Namely it returns: Meta data, rating data, tags, thumb_scoring, and review text.\n",
    "    \n",
    "    Args:\n",
    "        review_item: A single review list item containing all the appropraite HTML.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the meta data, rating data, tags, thumb_scoring, and review text\n",
    "        for a single review.\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(review_item, 'html.parser')\n",
    "    \n",
    "    course_and_date = parse_rating_header(soup)\n",
    "    \n",
    "    # TODO: Loses course reviews like 'CMSC131CMSC132' where students combined multiple courses they took\n",
    "    if course_and_date['course'] in courses:\n",
    "        \n",
    "        # Rating data\n",
    "        rating_data = parse_rating_data(soup)\n",
    "        \n",
    "        # Thumb Scoring\n",
    "        thumb_scoring = parse_thumb_scoring(soup)\n",
    "        \n",
    "        # Review body\n",
    "        review_text = parse_review_text(soup)\n",
    "        \n",
    "        # Generate a UUID for the review using the review's text - IMPORTANT FOR FINDING AGAIN\n",
    "        review_id = uuid.uuid5(uuid.NAMESPACE_URL, rmp_url + review_text['body'])\n",
    "        review_id_str = str(review_id)\n",
    "        \n",
    "        # Meta data - Stored in own table in the database\n",
    "        meta_data = parse_meta_data(soup, review_id_str, rmp_conn)\n",
    "        \n",
    "        # Tags - Stored in own table in the database\n",
    "        parse_review_tags(soup, review_id_str, rmp_conn)\n",
    "        \n",
    "        return {'review_id_data': {'review_id': review_id_str}, 'rating_data': rating_data, 'thumb_scoring': thumb_scoring,\n",
    "                'review_text': review_text, 'rating_header': course_and_date}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection 2.6: Parsing Utilities for an Entire RateMyProfessor Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section puts together the functionality of parsing the professor's stats and all of the reviews. We use Selenium to get all the reviews, then BeautifulSoup to actually parse each review. BeautifulSoup is used alone to parse the professor stats. For each page parsed (barring its existence), a dataframe holding the professor's overall stats and a dataframe holding the professor's parsed reviews are returned. However, even this is just for a single RateMyProfessor page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmp_prof_reviews(rmp_prof_url, selenium_driver, rmp_conn, prof_name, courses):\n",
    "    \"\"\"Gets all the RateMyProfessor reviews for a given professor and places into a\n",
    "    dataframe. Only grabs reviews for classes in the provided courses.\n",
    "    \n",
    "    Args:\n",
    "        rmp_prof_url: A string containing the RateMyProfessor URL for the professor.\n",
    "        prof_name: A string containing the professor's name.\n",
    "        prof_courses: List of courses to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing all the appropriate reviews.\n",
    "    \"\"\"\n",
    "    \n",
    "    reviews_html = load_all_rmp_reviews(rmp_prof_url, selenium_driver)\n",
    "    soup = BeautifulSoup(reviews_html, 'html.parser')\n",
    "    \n",
    "    first_name, last_name = prof_name.split(' ', 1)\n",
    "    \n",
    "    review_df = pd.DataFrame(columns=review_header_list)\n",
    "    \n",
    "    for review in soup.find_all('li'):\n",
    "        \n",
    "        if len(review.select('div[class*=\"Rating__StyledRating\"]')) != 0: # Avoid advertisement list items\n",
    "            data = parse_single_rmp_review(rmp_prof_url, str(review), courses, rmp_conn)\n",
    "\n",
    "            if data: # Since the review could be of an undesired course\n",
    "                flattened_data = {'full_name': prof_name}\n",
    "\n",
    "                for data_type, data_dict in data.items():\n",
    "                    \n",
    "                    for key, val in data_dict.items():\n",
    "                        flattened_data[key] = val\n",
    "\n",
    "                review_df = review_df.append(flattened_data, ignore_index=True)\n",
    "    \n",
    "    return review_df\n",
    "\n",
    "\n",
    "def parse_rmp_page(rmp_prof_url, headers, rmp_conn, selenium_driver, professor_name, courses):\n",
    "    \"\"\"Parses an entire RateMyProfessor professor page for overall stats & tags, and all\n",
    "    of their reviews. It will return two dataframes holding this information and insert\n",
    "    them into a database.\n",
    "    \n",
    "    Args:\n",
    "        rmp_prof_url: A string containing the RateMyProfessor URL for the professor.\n",
    "        headers: Request headers to use.\n",
    "        rmp_conn: Connection object to the RateMyProfessor database.\n",
    "        prof_name: A string containing the professor's name.\n",
    "        courses: List of courses to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of two dataframes, (overall statistics, all the reviews).\n",
    "    \"\"\"\n",
    "    \n",
    "    rmp_prof_page = requests.get(rmp_prof_url, headers=headers)\n",
    "    \n",
    "    if rmp_prof_page.status_code == 200:\n",
    "        soup = BeautifulSoup(rmp_prof_page.text, 'html.parser')\n",
    "        \n",
    "        # Professor stats\n",
    "        stats_container = soup.select('div[class*=\"TeacherInfo__StyledTeacher\"]')[0]\n",
    "        \n",
    "        prof_stats = get_rmp_prof_stats(str(stats_container))\n",
    "        \n",
    "        get_rmp_prof_top_tags(str(stats_container), professor_name, rmp_conn)\n",
    "        \n",
    "        overall_df = rmp_prof_overall_to_dataframe(professor_name, prof_stats)\n",
    "        insert_dataframe_into_db(rmp_conn, overall_df, 'professor_stats')\n",
    "        \n",
    "        # Professor reviews\n",
    "        all_reviews_df = get_rmp_prof_reviews(rmp_prof_url, selenium_driver, rmp_conn, professor_name, courses)\n",
    "        insert_dataframe_into_db(rmp_conn, all_reviews_df, 'reviews')\n",
    "        \n",
    "        return (overall_df, all_reviews_df)\n",
    "    else:\n",
    "        print(\"Error opening the RateMyProfessor professor page\")\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection 2.7: Scrape and Parse All Professors Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have functionality to parse **ALL** the professors you want from RateMyProfessor and gather up their overall stats and reviews. The `fill_nonexistant_rmp_data` is for still returning some data about professors who didn't have RateMyProfessor pages. We record this data so we don't check for it again later and for statistics' sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nonexistant_rmp_data(rmp_conn, professor):\n",
    "    \"\"\"Marks a professor as not having a page and fills professor's overall statistics dataframe\n",
    "    with empty values so that it may be placed into the database and not re-queried for later.\n",
    "    \n",
    "    Args:\n",
    "        rmp_db: Connection object to the RateMyProfessor database.\n",
    "        professor: String containing the name of the professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    empty_stats = {'rating': 0, 'take_again': 0, 'difficulty': 0, 'rating_count': 0}\n",
    "    \n",
    "    # Professor stats\n",
    "    overall_df = rmp_prof_overall_to_dataframe(professor, empty_stats, page_exists=0)\n",
    "    insert_dataframe_into_db(rmp_conn, overall_df, 'professor_stats')\n",
    "    \n",
    "    return None\n",
    "    \n",
    "    \n",
    "def parse_rmp_all_professors(rmp_db_filepath, professors, provided_courses, force_scrape=False):\n",
    "    \"\"\"Scrapes and parses all professors, storing the data in a database and returning a\n",
    "    list of dataframes for stats and reviews.\n",
    "    \n",
    "    Args:\n",
    "        rmp_db_filepath: String containing the filepath to the appropriate database.\n",
    "        professors: Dictionary of professors to list of courses.\n",
    "        force_scrape (optional, default=False): Forces a scrape of RateMyProfessors even if already done.\n",
    "        \n",
    "    Returns:\n",
    "        The tuple (stats, reviews) where each is a list of dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_major_stats = []\n",
    "    all_major_reviews = []\n",
    "    \n",
    "    rmp_db = create_connection(rmp_db_filepath)\n",
    "    \n",
    "    if should_scrape_rmp:\n",
    "        selenium_driver = start_selenium()\n",
    "    \n",
    "    try:\n",
    "        for professor, courses in professors.items():\n",
    "            overall_stats_df = None\n",
    "            all_reviews_df = None\n",
    "\n",
    "            # Read from database if the professor has already been scraped (only checks stats for confirmation)\n",
    "            if not should_scrape_rmp and is_professor_scraped(rmp_db, professor):\n",
    "                overall_stats_df = get_professor_stats_from_db(rmp_db, professor)\n",
    "                all_reviews_df = get_professor_reviews_from_db(rmp_db, professor)\n",
    "\n",
    "                # Keep track of the dataframes for each professor\n",
    "                all_major_stats.append(overall_stats_df)\n",
    "                all_major_reviews.append(all_reviews_df)\n",
    "\n",
    "            elif should_scrape_rmp:\n",
    "                # Get all the data from the professor's RateMyProfessor page\n",
    "                prof_rmp_urls = query_rmp_for_professor_url(professor, headers, params)\n",
    "\n",
    "                # If the professor has a RateMyProfessor page\n",
    "                for url in prof_rmp_urls:\n",
    "                    \n",
    "                    overall_stats_df, all_reviews_df = parse_rmp_page(url, headers, rmp_db, selenium_driver, professor, provided_courses)\n",
    "\n",
    "                    # Keep track of the dataframes for each professor\n",
    "                    all_major_stats.append(overall_stats_df)\n",
    "                    all_major_reviews.append(all_reviews_df)\n",
    "                    \n",
    "                    # So we don't query RateMyProfessor too much\n",
    "                    time.sleep(1)\n",
    "\n",
    "                else:\n",
    "                    # Used to fill the stats table to show their page doesn't exist\n",
    "                    fill_nonexistant_rmp_data(rmp_db, professor)\n",
    "            else:\n",
    "                print(\"Error: Did not scrape RMP, but could not find RMP data in database.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Type error: \" + str(e))\n",
    "        traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        if should_store_data:\n",
    "            rmp_db.close()\n",
    "            \n",
    "        if should_scrape_rmp:\n",
    "            stop_selenium(selenium_driver)\n",
    "    \n",
    "        return (all_major_stats, all_major_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Collection Part 2.8: Scrape and Parse All Computer Science Professors from RateMyProfessor](#Data-Collection-Part-2.8:-Scrape-and-Parse-All-Computer-Science-Professors-from-RateMyProfessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put all of that functionality to work! Here we do **actual** work to scrape and parse professor stats and reviews for every CMSC professor. We only record reviews for courses that are within the `cmsc_course_ids` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmp_cmsc_stats, all_rmp_cmsc_reviews = parse_rmp_all_professors(cmsc_rmp_db_filepath, cmsc_professors, cmsc_course_ids)\n",
    "\n",
    "merged_rmp_cmsc_stats = pd.concat(all_rmp_cmsc_stats)\n",
    "merged_rmp_cmsc_reviews = pd.concat(all_rmp_cmsc_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_rmp_cmsc_stats))\n",
    "merged_rmp_cmsc_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_rmp_cmsc_reviews))\n",
    "merged_rmp_cmsc_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Collection Part 2.9: Scrape and Parse All Business Management Professors from RateMyProfessor](#Data-Collection-Part-2.9:-Scrape-and-Parse-All-Business-Management-Professors-from-RateMyProfessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do **actual** work to scrape and parse professor stats and reviews for every BMGT professor. We only record reviews for courses that are within the `bmgt_course_ids` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmp_bmgt_stats, all_rmp_bmgt_reviews = parse_rmp_all_professors(bmgt_rmp_db_filepath, bmgt_professors, bmgt_course_ids)\n",
    "\n",
    "merged_rmp_bmgt_stats = pd.concat(all_rmp_bmgt_stats)\n",
    "merged_rmp_bmgt_reviews = pd.concat(all_rmp_bmgt_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_rmp_bmgt_stats))\n",
    "merged_rmp_bmgt_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_rmp_bmgt_reviews))\n",
    "merged_rmp_bmgt_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Data Collection Part 3: Query and Parse Data from PlanetTerp](#Data-Collection-Part-3:-Query-and-Parse-Data-from-PlanetTerp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we collect data from our second source, [PlanetTerp via their API](https://api.planetterp.com/#planetterp-api). An [Application Programming Interface (API)](https://en.wikipedia.org/wiki/API) allows us to 'ask' PlanetTerp for the data we want through HTTP requests (mostly GET), making it a [RESTful API](https://en.wikipedia.org/wiki/Representational_state_transfer). This is a vastly different approach than with RateMyProfessor, because we do not actually have to load PlanetTerp's HTML pages in order to get data. Instead we send a GET request to URL ([an endpoint](https://api.planetterp.com/#get-courses)) and receive back data in a [JSON](https://www.json.org/json-en.html). To handle this, we make use of [Python's requests library](https://requests.readthedocs.io/en/master/).\n",
    "\n",
    "PlanetTerp is slightly different from the RateMyProfessors website because it does not contain tags to describe each professor, nor have data-packed reviews. We get reviews and data mostly through querying the API for each professor individually. As stated above, this data is sent as a JSON. Each JSON contains general professor statistics and data, along with a list of reviews. We parse each individual review and place it into a dictionary. We place those that correspond to the introductory courses we are looking at into a dataframe, which will hold all desired reviews. We also placed professor statistics into a separate dataframe. Both dataframes are saved to the database.\n",
    "\n",
    "We also query [PlantTerp for their grade data](https://api.planetterp.com/#get-grades), which will be discussed below.\n",
    "\n",
    "If you've like to interact with the PlantTerp, checkout the documentation linked above. We also recommend using [Postman](https://www.postman.com/downloads/) to make it easier to view data and send requests. An example query would look like this: https://api.planetterp.com/v1/professor?name=Mohammad+Nayeem+Teli&reviews=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 3.1: Setup and Utilities for PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://api.planetterp.com/#get-a-professor\n",
    "planetterp_api = \"https://api.planetterp.com/v1/professor\"\n",
    "pt_header = {'Accept': 'application/json'}\n",
    "params = {'reviews': 'true'}\n",
    "\n",
    "# Stats and reviews data\n",
    "stats_columns=['first_name', 'last_name', 'full_name', 'slug', 'review_count', 'type', 'page_exists']\n",
    "review_columns=['review_id', 'full_name', 'course', 'date', 'body', 'rating', 'expected_grade']\n",
    "\n",
    "# Grade data\n",
    "grades_list = ['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-',\n",
    "                  'D+', 'D', 'D-', 'F', 'W']\n",
    "\n",
    "grades_headers = ['course', 'semester', 'grade', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_date_to_unix(date_str):\n",
    "    \"\"\"Takes the PlanetTerp datetime string and converts to unix time. Assumes\n",
    "    It is already in UTC timezone.\n",
    "    \n",
    "    Args:\n",
    "        date_str: String containing a date time in the format \"%Y-%m-%dT%H:%M:%S\".\n",
    "        \n",
    "    Returns:\n",
    "        A unix timestamp real representing the time passed into the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Format: 2020-01-01T00:00:00\n",
    "    date_time_obj = datetime.datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    return date_time_obj.timestamp() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 3.2: Parsing PlanetTerp Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sample Query to PlanetTerp for a Professor](img/PT_professor_request.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a prettified layout of sample JSON data. As you can see, it is simply a dictionary of key, value pairs. This section purely focuses on the `reviews` list. Each review contains 6 keys, which need to be parsed. Review parsing is done by `parse_pt_single_review`, while `parse_pt_reviews` works to parse **all** reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Could simply use the review JSON provided, but may not be the format we want\n",
    "def parse_pt_single_review(review, courses):\n",
    "    \"\"\"Parses a single PlanetTerp review and places it into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        review: A dictionary or JSON object holding the review data.\n",
    "        review_id: A string holding an unique id for this review.\n",
    "        courses: List of course ids to determine if review wanted.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary holding review information.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_dict = {}\n",
    "    course = review.get('course')\n",
    "    \n",
    "    if course and course in courses:\n",
    "        review_dict = {'full_name': review.get('professor'), 'course': course,\n",
    "                       'body': review.get('review'), 'expected_grade': review.get('expected_grade', np.nan),\n",
    "                       'rating': review.get('rating')}\n",
    "\n",
    "        unix_time = pt_date_to_unix(review.get('created'))\n",
    "        review_dict['date'] = unix_time\n",
    "\n",
    "        # TODO: Important for getting the right reviews later\n",
    "        review_id = uuid.uuid5(uuid.NAMESPACE_URL, planetterp_api + review_dict['body'] + str(review_dict['date']))\n",
    "        review_id_str = str(review_id)\n",
    "        \n",
    "        review_dict['review_id'] = review_id_str\n",
    "        \n",
    "    return review_dict\n",
    "    \n",
    "    \n",
    "def parse_pt_reviews(reviews, courses):\n",
    "    \"\"\"Parses all reviews from PlanetTerp, placing those that are within the desired courses\n",
    "    into a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        reviews: A list of dictionaries, each dictionary representing a single review.\n",
    "        reviews_df: A dataframe to hold the reviews.\n",
    "        courses: The desired courses for which to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe containing all the reviews for a professor.\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_rating = 0\n",
    "    course_count = 0\n",
    "    \n",
    "    reviews_df = pd.DataFrame(columns=review_columns)\n",
    "    \n",
    "    for review in reviews:\n",
    "        \n",
    "        review_dict = parse_pt_single_review(review, courses)\n",
    "        \n",
    "        if bool(review_dict):\n",
    "            reviews_df = reviews_df.append(review_dict, ignore_index=True)\n",
    "            avg_rating = avg_rating + review_dict['rating']\n",
    "            course_count = course_count + 1\n",
    "            \n",
    "    if course_count != 0:\n",
    "        avg_rating = float(avg_rating) / course_count\n",
    "        \n",
    "    return (reviews_df, avg_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 3.3: Querying PlanetTerp for Professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we refer to the JSON example data above, this section parses the professor data and hands the `requests` list off to the functions above. If the professor couldn't be found, filler data is used to record that we did search PlanetTerp for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pt_for_professor(professor, courses):\n",
    "    \"\"\"Queries the PlanetTerp API for a given professor, gathering their stats\n",
    "    and reviews. It then returns two dataframes (stats, reviews).\n",
    "    \n",
    "    Args:\n",
    "        professor: String holding the name of the professor to query.\n",
    "        courses: List of course ids to look for in the reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (stats, reviews) of dataframes holding the stats and reviews data.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats_df = pd.DataFrame(columns=stats_columns)\n",
    "    reviews_df = pd.DataFrame()\n",
    "    \n",
    "    params['name'] = professor\n",
    "    \n",
    "    \n",
    "    response = requests.get(planetterp_api, headers=pt_header, params=params)\n",
    "    \n",
    "    first_name, last_name = professor.split(' ', 1)\n",
    "    prof_stats = {'first_name': first_name, 'last_name': last_name, \n",
    "                  'full_name': professor}\n",
    "    \n",
    "    # The professor may not exist in the PlanetTerp database (though this shouldn't occur)\n",
    "    if response.status_code == 200:\n",
    "        json = response.json()\n",
    "        \n",
    "        review_count = 0\n",
    "        avg_rating = None\n",
    "        reviews = json.get('reviews')\n",
    "        \n",
    "        # The professor may not have any reviews\n",
    "        if reviews:\n",
    "            review_count = len(reviews)\n",
    "            reviews_df, avg_rating = parse_pt_reviews(reviews, courses)\n",
    "            \n",
    "        stats_cont = {'slug': json.get('slug'), 'type': json.get('type'),\n",
    "                     'review_count': review_count, 'rating': avg_rating, 'page_exists': 1}\n",
    "        \n",
    "    else:\n",
    "        stats_cont = {'page_exists': 0, 'review_count': 0}\n",
    "        \n",
    "        \n",
    "    prof_stats.update(stats_cont)\n",
    "    stats_df = stats_df.append(prof_stats, ignore_index=True)\n",
    "    \n",
    "    return (stats_df, reviews_df)\n",
    "\n",
    "\n",
    "def query_pt_for_all_professors(professors, courses, db_filepath, force_query=False):\n",
    "    \"\"\"Queries PlanetTerp for all the professors provided, taking reviews that\n",
    "    correspond to the given courses, and places professor stats and \n",
    "    reviews into a database.\n",
    "    \n",
    "    Args:\n",
    "        professors: A list of strings containing professor names.\n",
    "        courses: A list of strings containing course ids.\n",
    "        db_filepath: A string holding the filepath to a database.\n",
    "        force_query (optional, default=False): Boolean to decied whether to force\n",
    "            query the PlanetTerp API.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple (stats, reviews) of lists containing all dataframes for\n",
    "        each professor stats and reviews respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_major_stats = []\n",
    "    all_major_reviews = []\n",
    "    \n",
    "    try:\n",
    "        pt_db = create_connection(db_filepath)\n",
    "        for professor in professors:\n",
    "            \n",
    "            if not force_query and is_professor_scraped(pt_db, professor):\n",
    "                \n",
    "                stats_df = get_professor_stats_from_db(pt_db, professor)\n",
    "                reviews_df = get_professor_reviews_from_db(pt_db, professor)\n",
    "\n",
    "                # Keep track of the dataframes for each professor\n",
    "                all_major_stats.append(stats_df)\n",
    "                all_major_reviews.append(reviews_df)\n",
    "                \n",
    "            else:\n",
    "                stats_df, reviews_df = query_pt_for_professor(professor, courses)\n",
    "\n",
    "                if not stats_df.empty:\n",
    "                    all_major_stats.append(stats_df)\n",
    "                    insert_dataframe_into_db(pt_db, stats_df, 'professor_stats')\n",
    "\n",
    "                if not reviews_df.empty:\n",
    "                    all_major_reviews.append(reviews_df)\n",
    "                    insert_dataframe_into_db(pt_db, reviews_df, 'reviews')\n",
    "\n",
    "                time.sleep(1) # To give some time to the PlanetTerp API\n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Type error: \" + str(e))\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:\n",
    "        if should_store_data:\n",
    "            pt_db.close()\n",
    "            \n",
    "        return (all_major_stats, all_major_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Part 3.4: Querying PlanetTerp for Grades Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A Sample Grades Request](img/PT_grades_request.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also chose to query PlanetTerp for grade data for courses. This returns a list of all sections of courses over the years, along with their respective grades. [You can read here for more data about their grade data](https://planetterp.com/about#credits). While this data is not ultimately utilized, we feel it useful to go over grabbing and parsing this data. Since we were looking at courses overall, we combined all sections of a course per semester. So, we have a grade count per course per semester. While we didn't use it, we feel others may benefit from the data, and it is within our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_semester_grades(course_df):\n",
    "    \"\"\"Sums up grades across the same course and semester and returns a\n",
    "    new dataframe containing this information. Course grades are originally\n",
    "    grouped by their section and professor, so we want to aggregate them.\n",
    "    \n",
    "    Args:\n",
    "        course_df: A dataframe holding grades per section and professor.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe where the identical courses and semesters have their\n",
    "        grades aggregated.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=course_df.columns)\n",
    "    semester_groups = course_df.groupby(['course', 'semester', 'grade']).sum().reset_index()\n",
    "    return semester_groups\n",
    "\n",
    "\n",
    "def accumulate_course_grades(course_grades_json):\n",
    "    \"\"\"Accumulates all the grades of a course into a dataframe, because course\n",
    "    grades will be separated out by their section and professor.\n",
    "    \n",
    "    Args:\n",
    "        course_grades_json: A dictionary from PlanetTerp API containing grade info\"\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe where all grades of the same course and semester are accumulated.\n",
    "    \"\"\"\n",
    "    \n",
    "    course_grades_dict =  {}\n",
    "    course_grades_df = pd.DataFrame(columns=grades_headers)\n",
    "    \n",
    "    # There is a course item for every semester and section\n",
    "    for course in course_grades_json:\n",
    "        course_grade_dict = {'semester': course['semester'], 'course': course['course']}\n",
    "        \n",
    "        # We want to keep things tidy and keep the grade as a variable, so a row per grade\n",
    "        # per course is inserted into the dataframe. Now we can query for all 'A's\n",
    "        for grade in grades_list:\n",
    "            course_grade_dict['grade'] = grade\n",
    "            course_grade_dict['count'] = course.pop(grade, 0)\n",
    "            \n",
    "            course_grades_df = course_grades_df.append(course_grade_dict, ignore_index=True)\n",
    "        \n",
    "    return sum_semester_grades(course_grades_df)\n",
    "    \n",
    "    \n",
    "def query_pt_for_course_grades(courses, db_filepath, force_query=False):\n",
    "    \"\"\"Queries PlanetTerp for the grades for each course, accumulates\n",
    "    all grades of identitical courses and semesters, and places into a database.\n",
    "    \n",
    "    Args:\n",
    "        courses: A list of course ids to query the grades PlantTerp for\n",
    "        db_filepath: A database filepath to open and insert data into\n",
    "        force_query (optional, default=False): Boolean determining whether\n",
    "            PlanetTerp should be queried, regardless of database info.\n",
    "            \n",
    "    Returns:\n",
    "        A dataframe of all course, semester grades accumulated.\n",
    "    \"\"\"\n",
    "    \n",
    "    pt_db = create_connection(db_filepath)\n",
    "    \n",
    "    grades_api = 'https://api.planetterp.com/v1/grades'\n",
    "    grades_params = {'course': None}\n",
    "    \n",
    "    all_course_grades = []\n",
    "    \n",
    "    try:\n",
    "        for course in courses:\n",
    "            \n",
    "            # Check whether we've already queried for this course\n",
    "            course_grades_df = get_course_grades_from_db(pt_db, course)\n",
    "            \n",
    "            if course_grades_df.empty:\n",
    "                course_grades_df = pd.DataFrame(columns=grades_header_dict.values())\n",
    "            \n",
    "            # Query the PlanetTerp API for data\n",
    "            if should_query_pt or course_grades_df.empty:\n",
    "                grades_params['course'] = course\n",
    "                response = requests.get(grades_api, headers=pt_header, params=grades_params)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    grade_data = response.json()\n",
    "                    \n",
    "                    # Accumulate the grade info for this course\n",
    "                    course_grades_df = accumulate_course_grades(grade_data)\n",
    "                    all_course_grades.append(course_grades_df)\n",
    "                    \n",
    "                    # Put the course grades into the database\n",
    "                    insert_dataframe_into_db(pt_db, course_grades_df, 'grades', column_headers=grades_headers)\n",
    "                    \n",
    "                    # Give the API a bit of time\n",
    "                    time.sleep(0.5)\n",
    "                    \n",
    "            # Already had data from databases\n",
    "            else:\n",
    "                all_course_grades.append(course_grades_df)\n",
    "                \n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Type error: \" + str(e))\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:\n",
    "        \n",
    "        if should_store_data:\n",
    "            pt_db.close()\n",
    "        \n",
    "        if len(all_course_grades) == 0:\n",
    "            print(\"Error getting any course grades\")\n",
    "            return None\n",
    "        \n",
    "        return pd.concat(all_course_grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Collection Part 3.4: Parse All Computer Science Professors from PlanetTerp](#Data-Collection-Part-3.4:-Parse-All-Computer-Science-Professors-from-PlanetTerp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're back to **actual** work! Here we query PlanetTerp for all CMSC professors and their respective stats and reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pt_cmsc_stats, all_pt_cmsc_reviews = query_pt_for_all_professors(cmsc_professors, cmsc_course_ids, cmsc_pt_db_filepath)\n",
    "all_pt_cmsc_grades = query_pt_for_course_grades(cmsc_course_ids, cmsc_pt_db_filepath)\n",
    "\n",
    "merged_pt_cmsc_stats = pd.concat(all_pt_cmsc_stats)\n",
    "merged_pt_cmsc_reviews = pd.concat(all_pt_cmsc_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_pt_cmsc_stats))\n",
    "merged_pt_cmsc_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_pt_cmsc_reviews))\n",
    "merged_pt_cmsc_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_pt_cmsc_grades))\n",
    "all_pt_cmsc_grades.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Collection Part 3.5: Parse All Business Management Professors from PlanetTerp](#Data-Collection-Part-3.5:-Parse-All-Business-Management-Professors-from-PlanetTerp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More **actual** work! Here we are querying PlanetTerp for all BMGT professors and their respective stats and reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pt_bmgt_stats, all_pt_bmgt_reviews = query_pt_for_all_professors(bmgt_professors, bmgt_course_ids, bmgt_pt_db_filepath)\n",
    "all_pt_bmgt_grades = query_pt_for_course_grades(bmgt_course_ids, bmgt_pt_db_filepath)\n",
    "\n",
    "merged_pt_bmgt_stats = pd.concat(all_pt_bmgt_stats)\n",
    "merged_pt_bmgt_reviews = pd.concat(all_pt_bmgt_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_pt_bmgt_stats))\n",
    "merged_pt_bmgt_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_pt_bmgt_reviews))\n",
    "merged_pt_bmgt_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_pt_bmgt_grades))\n",
    "all_pt_bmgt_grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Data Aggregation: Putting It All Together](#Data-Aggregation:-Putting-It-All-Together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To organize our dataframes, we filter the data we collected from RateMyProfessor, PlanetTerp, and data that was consistent between both these sources. We separate the data based on major as well. To finalize some of the data, we combine rating counts and sum the total as well as finding the average rating for each professor from both RateMyProfessor and PlanetTerp. Each individual data frame that is created in this section is explained in the Analysis portion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Across PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So that we can separate by major later\n",
    "merged_pt_bmgt_stats['major'] = 'bmgt'\n",
    "merged_pt_cmsc_stats['major'] = 'cmsc'\n",
    "\n",
    "merged_pt_bmgt_reviews['major'] = 'bmgt'\n",
    "merged_pt_cmsc_reviews['major'] = 'cmsc'\n",
    "\n",
    "all_pt_bmgt_grades['major'] = 'bmgt'\n",
    "all_pt_cmsc_grades['major'] = 'cmsc'\n",
    "\n",
    "# Combine both majors' stats, reviews, and grades from PlanetTerp\n",
    "all_pt_stats = merged_pt_bmgt_stats.append(merged_pt_cmsc_stats)\n",
    "all_pt_reviews = merged_pt_bmgt_reviews.append(merged_pt_cmsc_reviews)\n",
    "all_pt_grades = pd.concat([all_pt_cmsc_grades, all_pt_bmgt_grades])\n",
    "\n",
    "# So that we can separate data in dataframes from both sources\n",
    "all_pt_stats['source'] = 'pt'\n",
    "all_pt_reviews['source'] = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_pt_stats))\n",
    "all_pt_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_pt_reviews))\n",
    "all_pt_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_pt_grades))\n",
    "all_pt_grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Across RateMyProfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So that we can separate by major later\n",
    "merged_rmp_bmgt_stats['major'] = 'bmgt'\n",
    "merged_rmp_cmsc_stats['major'] = 'cmsc'\n",
    "\n",
    "# Get the grades for each RMP review from the RMP bmgt database\n",
    "\n",
    "merged_rmp_bmgt_reviews['major'] = 'bmgt'\n",
    "merged_rmp_cmsc_reviews['major'] = 'cmsc'\n",
    "\n",
    "\n",
    "# Grade data for BMGT reviews (which are not originally part of reviews, since they're meta data in RMP)\n",
    "rmp_review_grades = get_rmp_data_for_all_ids(bmgt_rmp_db_filepath, merged_rmp_bmgt_reviews, get_rmp_review_grade)\n",
    "\n",
    "# Want to merge these grades with their respective reviews. Changing the column to match the PT dataframe\n",
    "# merged_rmp_bmgt_reviews = pd.merge(rmp_review_grades, merged_rmp_bmgt_reviews, on='review_id', how='outer')\n",
    "bmgt_reviews_grades = pd.merge(rmp_review_grades, merged_rmp_bmgt_reviews, on='review_id', how='outer')\n",
    "bmgt_reviews_grades.rename(columns={'value': 'expected_grade'}, inplace=True)\n",
    "\n",
    "# Grade data for CMSC reviews (which are not originally part of reviews, since they're meta data in RMP)\n",
    "rmp_review_grades = get_rmp_data_for_all_ids(cmsc_rmp_db_filepath, merged_rmp_cmsc_reviews, get_rmp_review_grade)\n",
    "\n",
    "# Want to merge these grades with their respective reviews. Changing the column to match the PT dataframe\n",
    "# merged_rmp_cmsc_reviews = pd.merge(rmp_review_grades, merged_rmp_cmsc_reviews, on='review_id', how='outer')\n",
    "cmsc_reviews_grades = pd.merge(rmp_review_grades, merged_rmp_cmsc_reviews, on='review_id', how='outer')\n",
    "cmsc_reviews_grades.rename(columns={'value': 'expected_grade'}, inplace=True)\n",
    "\n",
    "# Combine both majors' stats, reviews, and grades from RMP\n",
    "all_rmp_stats = merged_rmp_bmgt_stats.append(merged_rmp_cmsc_stats)\n",
    "all_rmp_reviews = bmgt_reviews_grades.append(cmsc_reviews_grades)\n",
    "\n",
    "# So that we can separate data in dataframes from both sources\n",
    "all_rmp_reviews['source'] = 'rmp'\n",
    "all_rmp_stats['source'] = 'rmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_rmp_stats))\n",
    "all_rmp_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_rmp_reviews))\n",
    "all_rmp_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Across both RateMyProfessor and PlanetTerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns shared between both the RMP and PT professor stats tables\n",
    "shared_stats_cols = ['full_name', 'page_exists', 'rating', 'major', 'source']\n",
    "\n",
    "# Combine the professor stats from PlanetTerp and RMP\n",
    "all_stats = pd.concat([all_pt_stats[shared_stats_cols + ['review_count']], all_rmp_stats[shared_stats_cols + ['rating_count']]])\n",
    "\n",
    "# Combine the rating counts into a single column and sum the total\n",
    "all_stats.replace(np.nan, 0, inplace=True)\n",
    "all_stats['total_reviews'] = all_stats['review_count'] + all_stats['rating_count']\n",
    "all_stats.drop(['review_count', 'rating_count'], inplace=True, axis=1)\n",
    "\n",
    "# Average the rating given to the professor across both RMP and PT\n",
    "all_stats = all_stats.groupby(['full_name', 'major']).agg({'rating': 'mean', 'total_reviews': 'sum'}).reset_index()\n",
    "all_stats = all_stats[all_stats.total_reviews != 0]\n",
    "all_stats.rename(columns={'rating': 'avg_rating'}, inplace=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_stats))\n",
    "all_stats.head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns shared between both the RMP and PT reviews tables\n",
    "shared_review_cols = ['full_name', 'course', 'date', 'body', 'major', 'rating',\n",
    "                      'expected_grade', 'sentiment_score',\n",
    "                      'sentiment_ground_label', 'source', 'review_id']\n",
    "\n",
    "all_reviews = pd.concat([all_pt_reviews[shared_review_cols], all_rmp_reviews[shared_review_cols]])\n",
    "all_reviews['sentiment_ground_label'] = all_reviews['sentiment_ground_label'].astype(int)\n",
    "\n",
    "# Some grades are 'Other' or simply empty, so we put NaN in their place\n",
    "def remove_bad_grade_values(val):\n",
    "    if val not in grades_list:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "# TODO: Maybe could keep the non-grade values and be used another way?\n",
    "all_reviews['expected_grade'] = all_reviews['expected_grade'].map(remove_bad_grade_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_reviews))\n",
    "all_reviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Across the Majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cmsc_stats = all_stats[all_stats['major'] == 'cmsc']\n",
    "all_cmsc_reviews = all_reviews[all_reviews['major'] == 'cmsc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_cmsc_stats))\n",
    "all_cmsc_stats.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_cmsc_reviews))\n",
    "all_cmsc_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bmgt_stats = all_stats[all_stats['major'] == 'bmgt']\n",
    "all_bmgt_reviews = all_reviews[all_reviews['major'] == 'bmgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_bmgt_stats))\n",
    "all_bmgt_stats.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_bmgt_reviews))\n",
    "all_bmgt_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Analysis](#Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a recap we have the following dataframes at our disposal:\n",
    "* `all_stats`, `all_reviews` - Combination of majors and RMP with PT stats and reviews\n",
    "    * Stats headers: full name of the professor, major, average rating, total reviews\n",
    "    * Review headers: full name of the professor, major, course id, date (unix), body of the review, and the reviewer's grade\n",
    "* `all_bmgt_stats`, `all_cmsc_stats` - Combined professor statistics from both RMP and PT\n",
    "* `all_bmgt_reviews`, `all_cmsc_reviews` - Combined introductory course reviews from both RMP and PT\n",
    "\n",
    "* `all_rmp_stats`, `all_rmp_reviews` - Combined CMSC and BMGT stats and reviews from RMP\n",
    "    * Stats headers: first/last/full name of professor, major, their average quality rating, difficulty rating, rating count\n",
    "    * Review headers: review id, first/last/full name of professor, major, course id, date (unix), body of the review, quality rating, difficulty rating, thumb up/down\n",
    "* `all_rmp_bmgt_stats`, `all_rmp_cmsc_stats` - Professor statistics from RMP for both BMGT and CMSC\n",
    "* `all_rmp_bmgt_reviews`, `all_rmp_cmsc_reviews` - Course reviews for each major from PT\n",
    "\n",
    "* `all_pt_stats`, `all_pt_reviews` - Combined CMSC and BMGT professor stats and reviews from PT\n",
    "    * Stats headers: first/last/full name of professor, average rating, review count, type of faculty, and major\n",
    "    * Review headers: review id, full name of professor, course, date (unix), body of the review, rating, expected grade, and major\n",
    "* `all_pt_bmgt_stats`, `all_pt_cmsc_stats` - Professor statistics for each major from PT\n",
    "* `all_pt_bmgt_reviews`, `all_pt_cmsc_reviews` - Course reviews for each major from PT\n",
    "\n",
    "\n",
    "These grades are from the grades endpoint of PlanetTerp, and not from the reviews parsed.\n",
    "* `all_pt_grades` - Combined grades from the majors, data from PT\n",
    "    * Headers: course, semester, count of the amount per grade (A+ through W), and major\n",
    "* `all_pt_cmsc_grades`, `all_pt_bmgt_grades` - Grades per major from PT \n",
    "    * Headers: course, semester, count of the amount per grade (A+ through W)\n",
    "    \n",
    "Note the combined major dataframes have a `major` column, which is the only difference between the separated dataframes' columns.\n",
    "Also any databases that combines data from PlanetTerp and RateMyProfessor have a `source` column ('pt', 'rmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_stats.columns)\n",
    "print(all_reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_rmp_stats.columns)\n",
    "print(all_rmp_reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_pt_stats.columns)\n",
    "print(all_pt_reviews.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_pt_grades.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Breadth of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stat and Review Count Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames that contain the counts of each major's reviews and stats\n",
    "stats_df = pd.DataFrame(columns=['major', 'count'])\n",
    "stats_df['major'] = ['CMSC', 'BMGT']\n",
    "stats_df['count'] = [len(all_cmsc_stats), len(all_bmgt_stats)]\n",
    "\n",
    "reviews_df = pd.DataFrame(columns=['major', 'count'])\n",
    "reviews_df['major'] = ['CMSC', 'BMGT1']\n",
    "reviews_df['count'] = [len(all_cmsc_reviews), len(all_bmgt_reviews)]\n",
    "\n",
    "# Plot them out to visually compare\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "fig.suptitle('Comparing CMSC to BMGT in Professor and Review Count')\n",
    "ax[0].set(title=\"Review Count Comparison\")\n",
    "ax[1].set(title=\"Professor Count Comparison\")\n",
    "\n",
    "sns.barplot(x='major', y='count', data=reviews_df, ax=ax[0])\n",
    "sns.barplot(x='major', y='count', data=stats_df, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these graphs we can see that CMSC has BMGT 'beat' in both the reviews and professors rated count department. The left graph shows that there are roughly double the amount of reviews for CMSC courses than there are for BMGT courses. Additionally, the right graph shows that roughly double the amount of CMSC professors have been reviewed than BMGT professors. Again, this data is aggregated from both PlanetTerp and RateMyProfessor. We have also queried for the same amount of courses.\n",
    "\n",
    "We could infer this to mean that CMSC students are more likely to be posting reviews. It could also just mean that there are more CMSC students, and thus there are more reviews from them. Without exact numbers of the population of CMSC and BMGT students, it makes the comparison a little difficult. But it does give some insight into which major you're more likely to find reviews for the professor or course you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Grade Dispersion for Each Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame()\n",
    "\n",
    "# Get the grades from all the reviews, dropping reviews without a grade\n",
    "grades_df = all_reviews[['major', 'expected_grade']].copy().dropna()\n",
    "\n",
    "# Count how many of each grade per major\n",
    "grades_df['count'] = 0\n",
    "agg_grades_df = grades_df.groupby(['major', 'expected_grade']).count().reset_index()\n",
    "\n",
    "# How many grades total do we have from each major\n",
    "total_bmgt_grades = agg_grades_df.loc[agg_grades_df['major'] == 'bmgt']['count'].sum()\n",
    "total_cmsc_grades = agg_grades_df.loc[agg_grades_df['major'] == 'cmsc']['count'].sum()\n",
    "\n",
    "# Separate out the DataFrame so that it'll be easier to update values\n",
    "bmgt_grades_df = agg_grades_df.loc[agg_grades_df['major'] == 'bmgt'].copy()\n",
    "cmsc_grades_df = agg_grades_df.loc[agg_grades_df['major'] == 'cmsc'].copy()\n",
    "\n",
    "cmsc_grades_df.update(cmsc_grades_df['count'].divide(total_cmsc_grades))\n",
    "bmgt_grades_df.update(bmgt_grades_df['count'].divide(total_bmgt_grades))\n",
    "\n",
    "# Make it percentages\n",
    "cmsc_grades_df.update(cmsc_grades_df['count'].multiply(100))\n",
    "bmgt_grades_df.update(bmgt_grades_df['count'].multiply(100))\n",
    "\n",
    "# Bring them back together with the percentage values\n",
    "agg_grades_df = pd.concat([cmsc_grades_df, bmgt_grades_df])\n",
    "\n",
    "# Plot out the grade dispersion per major\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "sns.barplot(ax=ax, data=agg_grades_df, x='expected_grade', y='count', hue='major', order=grades_list)\n",
    "\n",
    "ax.set(title=\"Grade Distribution of Majors\", xlabel=\"Grade\", ylabel=\"Percentage of Grade (%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've plotted the percentage of grades per major. Due to the unequal amount of CMSC and BMGT reviews, we can't simply compare the counts of each grade per major. Instead we use the percentage of each grade per major, to be more representative. We see that the majority of grades for both majors are typically within the A+ to B range. BMGT does appear to have double the amount of C grades than CMSC.\n",
    "\n",
    "Again, this data does need to be taken with a grain of salt. It's likely we have [missing data not at random](https://en.wikipedia.org/wiki/Missing_data#Missing_not_at_random) because students may not post reviews with poor grades. This grade data is strictly from scraped reviews with a reported grade in the range A+ to W. We'd also like to note that we have removed the reported grades of 'Other' or 'Rather not say.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews and Data in Relation to Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall start ~August 20 and after\n",
    "fall_start = datetime.datetime(year=2020, month=8, day=20)\n",
    "# Winter start ~January 2nd\n",
    "winter_start = datetime.datetime(year=2020, month=1, day=2)\n",
    "# Spring start ~January 20th\n",
    "spring_start = datetime.datetime(year=2020, month=1, day=20)\n",
    "# Summer start ~June 1st\n",
    "summer_start = datetime.datetime(year=2020, month=6, day=1)\n",
    "\n",
    "# We want to establish semester as a category, and to enforce an order\n",
    "semester_list = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "semester_type = CategoricalDtype(categories=semester_list, ordered=True)\n",
    "\n",
    "def get_semester_from_unix(timestamp):\n",
    "    \"\"\"Determines what semester a review was posted - note, this is a rough\n",
    "    estimate. Also note, it may be students post after their semester is over \n",
    "    and the next has started.\n",
    "    \n",
    "    Args:\n",
    "        timestamp: A unix timestamp as an integer\n",
    "    \n",
    "    Returns:\n",
    "        A string containing the respective semester to timestamp.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_date = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    review_year = review_date.year\n",
    "    \n",
    "    if review_date.month >= fall_start.month:\n",
    "        return 'Fall'\n",
    "    elif review_date.month >= summer_start.month:\n",
    "        return 'Summer'\n",
    "    elif review_date.month >= spring_start.month or  \\\n",
    "    (review_date.month == spring_start.month and review_date.day >= spring_start.day):\n",
    "        return 'Spring'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_month_from_unix(timestamp):\n",
    "    \"\"\"Determines the month from a given unix timestamp.\"\"\"\n",
    "    \n",
    "    date = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    return date.strftime('%B')\n",
    "\n",
    "\n",
    "def get_year_from_unix(timestamp):\n",
    "    \"\"\"Determines the year from a given unix timestamp.\"\"\"\n",
    "    \n",
    "    date = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    return date.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Grade Dispersion Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "grade_type = CategoricalDtype(categories=grades_list, ordered=True)\n",
    "\n",
    "# Get the CMSC grades and find the year of each review\n",
    "cmsc_review_time = all_cmsc_reviews[['expected_grade', 'date', 'rating']].copy()\n",
    "cmsc_review_time['year'] = cmsc_review_time['date'].apply(lambda date: get_year_from_unix(date))\n",
    "\n",
    "# Get the amount of grades per grade per year\n",
    "cmsc_review_year = cmsc_review_time.groupby(['year', 'expected_grade']).size().reset_index(name='count')\n",
    "cmsc_review_year.rename(columns={'expected_grade': 'Grade'}, inplace=True)\n",
    "\n",
    "# Want to use a category for the grade to keep it ordered\n",
    "cmsc_review_year['Grade'] = cmsc_review_year['Grade'].astype(grade_type)\n",
    "\n",
    "# Plot the CMSC grades over time\n",
    "sns.swarmplot(data=cmsc_review_year, x='year', y='count', hue='Grade', palette=sns.color_palette('husl', n_colors=14), ax=ax[0])\n",
    "ax[0].set(title=\"CMSC Grade Dispersion Over Time\", ylabel='Count of Grade Occurence', xlabel='Year')\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "\n",
    "\n",
    "# Get the BMGT grades and find the year of each review\n",
    "bmgt_review_time = all_bmgt_reviews[['expected_grade', 'date', 'rating']].copy()\n",
    "bmgt_review_time['year'] = bmgt_review_time['date'].apply(lambda date: get_year_from_unix(date))\n",
    "\n",
    "# Get the amount of grades per grade per year\n",
    "bmgt_review_year = bmgt_review_time.groupby(['year', 'expected_grade']).size().reset_index(name='count')\n",
    "bmgt_review_year.rename(columns={'expected_grade': 'Grade'}, inplace=True)\n",
    "\n",
    "# Want to use a category for the grade to keep it ordered\n",
    "bmgt_review_year['Grade'] = bmgt_review_year['Grade'].astype(grade_type)\n",
    "\n",
    "# Plot the BMGT grades over time\n",
    "sns.swarmplot(data=bmgt_review_year, x='year', y='count', hue='Grade', palette=sns.color_palette('husl', n_colors=14), ax=ax[1])\n",
    "ax[1].set(title=\"BMGT Grade Dispersion Over Time\", ylabel='Count of Grade Occurence', xlabel='Year')\n",
    "ax[1].set_ylim([0, 30])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs depict the grade count of majors over the years, as reported from RateMyProfessor and PlanetTerp. Interestingly, for most years, A seems to be the most frequent grade for CMSC student reviews. This does not hold for the BMGT major, where A drops to lower reported counts between 2011 and 2018. We should also point out that these graphs on the same scale, but as stated earlier, CMSC does have more reviews and reported grades. But from the data, it appears that CMSC reports better grades in the A range. However, we also see a larger gap between the grade frequency in CMSC, especially evident in 2018 through 2020. Overall, A count seems to have an increasing trend in CMSC, while such a trend is not present in BMGT and it remains mostly steady."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Review Dispersion Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a month category for dataframes\n",
    "months = [calendar.month_name[i] for i in range(1, 13)]\n",
    "month_type = CategoricalDtype(categories=months, ordered=True)\n",
    "\n",
    "\n",
    "# Grab the pertinent columns and get the month, year, and semester for each date\n",
    "review_time_df = all_reviews[['date', 'major', 'source', 'rating']].copy().dropna()\n",
    "review_time_df['month'] = review_time_df['date'].apply(lambda date: get_month_from_unix(date))\n",
    "review_time_df['year'] = review_time_df['date'].apply(lambda date: get_year_from_unix(date))\n",
    "\n",
    "# Need to make month categorical to make it ordered in the graph\n",
    "review_time_df['month'] = review_time_df['month'].astype(month_type)\n",
    "\n",
    "# Need to make semester categorical to make it ordered in the graph\n",
    "review_time_df['semester'] = review_time_df['date'].apply(lambda date: get_semester_from_unix(date))\n",
    "review_time_df['semester'] = review_time_df['semester'].astype(semester_type)\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 24))\n",
    "\n",
    "# Reviews per month per major\n",
    "review_month_major = review_time_df.groupby(['month', 'major']).size().reset_index(name='count')\n",
    "sns.barplot(ax=ax[0], data=review_month_major, x='month', y='count', hue='major')\n",
    "ax[0].set(title=\"Reviews per Month per Major\", xlabel='', ylabel='Review Count')\n",
    "ax[0].legend(title='Major')\n",
    "\n",
    "# Review per semester per major\n",
    "review_semester_major = review_time_df.groupby(['semester', 'major']).size().reset_index(name='count')\n",
    "sns.barplot(ax=ax[1], data=review_semester_major, x='semester', y='count', hue='major')\n",
    "ax[1].set(title=\"Reviews per Semester per Major\", xlabel='Semester', ylabel='Review Count')\n",
    "ax[1].legend(title='Major')\n",
    "\n",
    "# Reviews per year per major\n",
    "review_year_major = review_time_df.groupby(['year', 'major']).size().reset_index(name='count')\n",
    "sns.barplot(ax=ax[2], data=review_year_major, x='year', y='count', hue='major')\n",
    "ax[2].set(title=\"Reviews per Year per Major\", xlabel='Year', ylabel='Review Count')\n",
    "ax[2].legend(title='Major')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these graphs we can see the dispersion of reviews over time. The first graph is by month, regardless of the year. We see most reviews seem to be posted in December and May, for both majors. May marks the end of the the Spring semester and December marks the end of the Fall semester, so this is not all too surprising. This lines up roughly with the reviews posted per semester, as seen in the second graph. Not all too surprising, but no reviews were posted in the short amount of time that is the Winter semester (January 1st start date to roughly January 20th). Thus, the first two graphs definitely have a bimodal distribution. Lastly, we show the amount of reviews posted per yer in the last graph. We see an increasing trend over the years for CMSC reviews posted, although BMGT reviews tend to have little variation. These last 2-3 years for CMSC has certainly seen a boom in reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Review Rating Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(25, 15))\n",
    "\n",
    "# Get the median rating of all professors in a major\n",
    "med_cmsc_prof_rating = all_cmsc_stats['avg_rating'].median()\n",
    "med_bmgt_prof_rating = all_bmgt_stats['avg_rating'].median()\n",
    "avg_cmsc_prof_rating = all_cmsc_stats['avg_rating'].mean()\n",
    "avg_bmgt_prof_rating = all_bmgt_stats['avg_rating'].mean()\n",
    "\n",
    "# Group CMSC by the year and rating to see dispersion over the years\n",
    "cmsc_rating_time = cmsc_review_time.copy()\n",
    "cmsc_rating_time = cmsc_rating_time.groupby(['year', 'rating']).size().reset_index(name='count')\n",
    "sns.boxplot(data=cmsc_rating_time, x='year', y='rating', ax=ax[0])\n",
    "\n",
    "ax[0].axhline(y=med_cmsc_prof_rating, linestyle='dashed', label='Median Prof. Rating')\n",
    "ax[0].axhline(y=avg_cmsc_prof_rating, linestyle='solid', color='red', label='Mean Prof. Rating')\n",
    "ax[0].set(title=\"CMSC Review Rating Dispersion Over Time\", xlabel='Year', ylabel='Rating')\n",
    "labels = ['Median Professor Rating', 'Mean Prof. Rating']\n",
    "handles, _ = ax[0].get_legend_handles_labels()\n",
    "ax[0].legend(handles = handles[0:], labels=labels)\n",
    "\n",
    "# Group BMGT reviews by the year and rating to see dispersion over the years\n",
    "bmgt_rating_time = bmgt_review_time.copy()\n",
    "bmgt_rating_time = bmgt_rating_time.groupby(['year', 'rating']).size().reset_index(name='count')\n",
    "sns.boxplot(data=bmgt_rating_time, x='year', y='rating', ax=ax[1])\n",
    "\n",
    "ax[1].axhline(y=med_bmgt_prof_rating, linestyle='dashed', label='Median Prof. Rating')\n",
    "ax[1].axhline(y=avg_bmgt_prof_rating, linestyle='solid', color='red', label='Mean Prof. Rating')\n",
    "ax[1].set(title=\"BMGT Review Rating Dispersion Over Time\", xlabel='Year', ylabel='Rating')\n",
    "labels = ['Median Professor Rating', 'Mean Prof. Rating']\n",
    "handles, _ = ax[1].get_legend_handles_labels()\n",
    "ax[1].legend(handles = handles[0:], labels=labels)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs depict the dispersion of ratings given to professors by students of each major over the years. While there is higher dispersion in the earlier years, such as from 2004 to 2013, we see it start to level out to around a rating 3.0 in both majors. Skewed dispersions, such as in 2004 in both graphs or 2009 and 2013 of BMGT can be explained by the low amount of reviews those years (as seen in the graph above). We've also plotted the average and median professor rating for each major. Due to their close similarity, there is likely no high amount of outliers skewing the data (though this can be interpreted from the boxplots as well). So, it appears both majors have arrived roughly at the same professor rating by 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews and Ratings By the Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(2, 1, figsize=(25, 24))\n",
    "colors = {'RateMyProfessor': 'C0', 'PlanetTerp': 'C1'}\n",
    "\n",
    "# Groups reviews by year and source\n",
    "review_source = review_time_df.groupby(['year', 'source']).size().reset_index(name='count')\n",
    "review_source.loc[review_source['source'] == 'rmp', 'full_source'] = 'RateMyProfessor'\n",
    "review_source.loc[review_source['source'] == 'pt', 'full_source'] = 'PlanetTerp'\n",
    "\n",
    "# Plots out this grouping distribution\n",
    "sns.barplot(ax=ax[0], data=review_source, x='year', y='count', hue='full_source', palette=colors)\n",
    "ax[0].set(title=\"Reviews per Year per Source\", xlabel='Year', ylabel='Review Count')\n",
    "ax[0].legend(title='Source')\n",
    "\n",
    "# Groups years by their rating, source, and year to get a distribution of rating per source\n",
    "rating_source = review_time_df[['source', 'year', 'rating']].copy()\n",
    "rating_source.loc[rating_source['source'] == 'rmp', 'full_source'] = 'RateMyProfessor'\n",
    "rating_source.loc[rating_source['source'] == 'pt', 'full_source'] = 'PlanetTerp'\n",
    "rating_source = rating_source.groupby(['rating', 'year', 'full_source']).size().reset_index(name='count')\n",
    "\n",
    "# Plots out this grouping\n",
    "sns.boxplot(data=rating_source, x='year', y='rating', hue='full_source', ax=ax[1], palette=colors)\n",
    "ax[1].set(title=\"Rating Distribution per Year per Source\", xlabel='Year', ylabel='Rating Score')\n",
    "ax[1].legend(title='Source')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we examine the reviews by their source, e.g. RateMyProfessor or PlanetTerp. First we see that PlanetTerp doesn't have reviews earlier than 2007, so RateMyProfessor has been around longer most likely. In the first graph we see that PlanetTerp does have a bimodal distribution, with the first majority of reviews between 2008 and 2012, then another rise from 2016 to 2020. We see reviews from RateMyProfessor greatly jump from 2018 to 2020 as well. This could mean that you may want to visit RateMyProfessor first for you reviews. Although PlanetTerp has a decent amount in these years as well.\n",
    "\n",
    "In the second graph we show the rating dispersion of each source over the years. This was to see if one source was likely more negative or positive than the other. While there are heavy skews in the data in 2004 and 2009 through 2011 for RateMyProfessor, we can see this is due to little reviews. Otherwise, for the most part, both sources are rating their professors roughly the same, with the last time RateMyProfessor being slightly harsher on professors in 2016. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grades by Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_courses=[]\n",
    "match_grades=[]\n",
    "\n",
    "dic={'A+': 100, 'A': 96, 'A-': 92, 'B+': 88, 'B': 84, 'B-': 80, 'C+': 77,'C':74, 'C-': 70, 'D+': 67, 'D': 64, 'D-': 60, 'F': 50}\n",
    "\n",
    "for course, bin in all_reviews.groupby('course'):\n",
    "    grades_classes = bin['expected_grade'].dropna()\n",
    "    for grade in grades_classes:\n",
    "        if (grade!='W'):\n",
    "            match_courses.append(course)\n",
    "            match_grades.append(dic[grade])\n",
    "            \n",
    "            \n",
    "data={'Course': match_courses, 'Grade': match_grades}\n",
    "courses_to_grades = pd.DataFrame(data)\n",
    "\n",
    "fix, ax = plt.subplots(1, 1, figsize=(15,5))\n",
    "ax.set(xlabel='Course', ylabel='Grade', title='Concentration of Grades by Course')\n",
    "\n",
    "sns.violinplot(x='Course', y='Grade',data=courses_to_grades, ax=ax)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is violin plot illustrating grades, out of 100, by class. We ran into a lot of missing data here, as many students left reviews without adding leaving their expected grade. Unfortunately, we had to omit these from the data. W's (withdraws) were also left out (the alternative was to cast them to 0's). The tips of the violins seem to extend past 100; this is simply how seaborn renders violins, the maximum grade plotted was a 100. Since grades are represented as letters in the databases, we had to map them to their analogous numerical grade: A+'s to 100, A' to 97, and so on, down to F's being 50's.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Analyzing Word Frequencies and Rudimentary Sentiment Analysis in Reviews](#Analyzing-Word-Frequencies-and-Rudimentary-Sentiment-Analysis-in-Reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Fill in section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [spaCy](https://spacy.io/) to process text. Here we are mainly using to first get the lemmas for each word in the review. The lemma is essentially the 'root' of a word - it normalizes the tense, plurality, etc. We also remove typical stop words in English, such as 'the' or 'a'. [More about lemmatization can be read about here.](https://en.wikipedia.org/wiki/Lemmatisation) \n",
    "\n",
    "We need to turn words into their lemma because word forms may vary across reviews, but are in essence the same. It also makes checking for words simpler, such that we don't need to check every word for every form of it. Additionally, the removal of stop words is to remove 'useless' data. There isn't much to learn from the use of words like 'the' in a sentence, so we just remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Need to run python -m spacy download en_core_web_sm (also a medium and large dataset)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
    "def tokenize_lemmatize_text(text):\n",
    "    tokens = nlp(text)\n",
    "    \n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != '-PRON-' else word.lower_ for word in tokens]\n",
    "    tokens = [lemma for lemma in tokens if lemma not in spacy_stopwords and lemma not in punctuation]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Positive and Negative Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_dict(filepath, word_dict):\n",
    "    \"\"\"Saves word frequency dictionaries to a pickle file.\"\"\"\n",
    "    pickle.dump(word_dict, open(filepath, 'wb'))\n",
    "    \n",
    "    \n",
    "def read_word_dict_file(filepath):\n",
    "    \"\"\"Reads a word frequency dictionary from a pickle file.\"\"\"\n",
    "    return pickle.load(open(filepath, 'rb'))\n",
    "\n",
    "\n",
    "def read_lexicon(filepath):\n",
    "    \"\"\"Read a lexicon full of words from a file and insert them into\n",
    "    a list to return. Simple \\n separation.\n",
    "    \n",
    "    Args:\n",
    "        filepath: A string containing the filepath to the lexicon.\n",
    "        \n",
    "    Returns:\n",
    "        A list of words (one per line).\n",
    "    \"\"\"\n",
    "    \n",
    "    lexicon = []\n",
    "    \n",
    "    with open(filepath, 'r') as fp:\n",
    "        all_words = fp.readlines()\n",
    "        for word in all_words:\n",
    "            lexicon.append(word.strip())\n",
    "            \n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive words\n",
    "positive_words = read_lexicon('./data/lexicon/positive-words.txt')\n",
    "positive_words.append('funny')\n",
    "positive_words.remove('tough')\n",
    "\n",
    "# Load negative words\n",
    "negative_words = read_lexicon('./data/lexicon/negative-words.txt')\n",
    "negative_words.append('tough')\n",
    "negative_words.remove('funny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Scoring and Labeling the Sentiment of Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sentiment_score_labels(review_df, source, major):\n",
    "    \"\"\"Handles saving the sentiment scores to the correct database,\n",
    "    depending on the major and source of the review.\n",
    "    \n",
    "    Args:\n",
    "        review_df: Dataframe of reviews\n",
    "        source: Source of the reviews to save ('pt', 'rmp')\n",
    "        major: The major of the reviews to save ('bmgt', 'cmsc')\n",
    "    \"\"\"\n",
    "    \n",
    "    if not should_store_data:\n",
    "        return\n",
    "    \n",
    "    if source == 'pt':\n",
    "        if major == 'bmgt':\n",
    "            db_filepath = bmgt_pt_db_filepath\n",
    "        else:\n",
    "            db_filepath = cmsc_pt_db_filepath\n",
    "    else:\n",
    "        if major == 'bmgt':\n",
    "            db_filepath = bmgt_rmp_db_filepath\n",
    "        else:\n",
    "            db_filepath = cmsc_rmp_db_filepath\n",
    "            \n",
    "    db_conn = create_connection(db_filepath)\n",
    "    \n",
    "    try:\n",
    "        insert_all_review_sentiment_labels(db_conn, review_df)\n",
    "    except Exception as e:\n",
    "        print(\"Type error: \" + str(e))\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:\n",
    "        if db_conn:\n",
    "            db_conn.close()\n",
    "            \n",
    "            \n",
    "def update_word_dict(word_dict, word):\n",
    "    \"\"\"Updates a counting dictionary depending on if key is present.\"\"\"\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = 1\n",
    "    else:\n",
    "        word_dict[word] = word_dict[word] + 1\n",
    "        \n",
    "    return word_dict\n",
    "\n",
    "\n",
    "def normalize_score(score, max_score, min_score):\n",
    "    \"\"\"Normalizes the score to [-1, 1] range.\"\"\"\n",
    "    denom = (max_score - min_score)\n",
    "    \n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    norm_score = 2 * ((score - min_score) / denom) - 1\n",
    "    \n",
    "    return norm_score\n",
    "\n",
    "\n",
    "def get_label_from_score(score):\n",
    "    \"\"\"Returns a label for a score, where 1 is positive,\n",
    "    0 is neutral, and -1 is negative.\"\"\"\n",
    "    \n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    \n",
    "    return score\n",
    "    \n",
    "    \n",
    "def score_review(review_body, positive_dict, negative_dict, all_word_dict):\n",
    "    \"\"\"A rudimentary sentiment scoring algorithm, which subtracts from the\n",
    "    score when a negative word is present and adds to the score when a \n",
    "    positive word is present. No POS is used. Words are lemmatized.\n",
    "    \n",
    "    Args:\n",
    "        review_body: A string containing the body of the review.\n",
    "        \n",
    "    Returns:\n",
    "        An integer score\n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    tokens = tokenize_lemmatize_text(review_body)\n",
    "    \n",
    "    for token in tokens:\n",
    "        all_word_dict = update_word_dict(all_word_dict, token)\n",
    "        \n",
    "        if token in positive_words:\n",
    "            positive_dict = update_word_dict(positive_dict, token)\n",
    "            score = score + 1\n",
    "        \n",
    "        elif token in negative_words:\n",
    "            negative_dict = update_word_dict(negative_dict, token)\n",
    "            score = score - 1\n",
    "            \n",
    "    return (score, positive_dict, negative_dict, all_word_dict)\n",
    "\n",
    "\n",
    "def score_all_reviews(review_df):\n",
    "    \"\"\"Scores each review as in range [-1, 1], and also keeps\n",
    "    track of the frequencies of words for all, positive, and negative words.\n",
    "    \n",
    "    Args:\n",
    "        review_df: A dataframe containing reviews.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of an updates review dataframe with scores, a positive word frequency dictionary,\n",
    "        a negative word frequency dictionary, and all word dictionary frequency.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = []\n",
    "    positive_dict = {}\n",
    "    negative_dict = {}\n",
    "    all_word_dict = {}\n",
    "    \n",
    "    for row in review_df.itertuples():\n",
    "        (score, positive_dict, negative_dict, all_word_dict) = score_review(row.body, positive_dict, negative_dict, all_word_dict)\n",
    "        scores.append(score)\n",
    "        \n",
    "    # TODO: Normalize scores if we want a range of positive/negativeness?\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    norm_scores = [normalize_score(score, max_score, min_score) for score in scores]\n",
    "    \n",
    "    # Label the reviews\n",
    "    labels = [get_label_from_score(score) for score in scores]\n",
    "    \n",
    "    review_df['sentiment_score'] = scores\n",
    "    review_df['sentiment_ground_label'] = labels\n",
    "    \n",
    "    return (review_df, positive_dict, negative_dict, all_word_dict)\n",
    "\n",
    "\n",
    "def reviews_need_sentiment(sentiment_df):\n",
    "    \"\"\"If the ground labels are full of empty strings or null values, then\n",
    "    the reviews have not been scored and labeled yet.\n",
    "    \n",
    "    Args:\n",
    "        sentiment_df: A dataframe holding reviews\n",
    "    \n",
    "    Returns:\n",
    "        True if there are no sentiment ground labels, false otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    empty_sentiment_labels = (sentiment_df['sentiment_ground_label'].values == '').sum()\n",
    "    null_sentiment_labels = sentiment_df['sentiment_ground_label'].isnull().sum()\n",
    "    \n",
    "    return null_sentiment_labels != 0 or empty_sentiment_labels != 0\n",
    "    \n",
    "    \n",
    "def score_and_label_reviews(sentiment_df, major, dict_fp):\n",
    "    \"\"\"Scores and labels the provided reviews from the sentiment DataFrame, storing them\n",
    "    into a database, along with gathering word frequency dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        sentiment_df: A dataframe holding reviews\n",
    "        major: A string containing the major name ('cmsc', 'bmgt')\n",
    "        dict_fp: A string holding the start of the filepath to the dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of an updated sentiment dataframe with scores and labels, along with\n",
    "        the word frequency dictionaries - (df, positive, negative, all)\n",
    "    \"\"\"\n",
    "    \n",
    "    (sentiment_df, positive_dict, negative_dict, all_word_dict) = score_all_reviews(sentiment_df)\n",
    "\n",
    "    pt_reviews = sentiment_df.loc[sentiment_df['source'] == 'pt']\n",
    "    save_sentiment_score_labels(pt_reviews, 'pt', major)\n",
    "\n",
    "    rmp_reviews = sentiment_df.loc[sentiment_df['source'] == 'rmp']\n",
    "    save_sentiment_score_labels(rmp_reviews, 'rmp', major)\n",
    "\n",
    "    save_word_dict(dict_fp + 'positive.p', positive_dict)\n",
    "    save_word_dict(dict_fp + 'negative.p', negative_dict)\n",
    "    save_word_dict(dict_fp + 'all.p', all_word_dict)\n",
    "    \n",
    "    return (sentiment_df, positive_dict, negative_dict, all_word_dict)\n",
    "    \n",
    "    \n",
    "def read_word_freq_dicts(dict_fp):\n",
    "    \"\"\"Reads the positive, negative, and all word word frequency\n",
    "    dictionaries and returns them in this order as a tuple.\"\"\"\n",
    "    \n",
    "    positive_dict = read_word_dict_file(dict_fp + 'positive.p')\n",
    "    negative_dict = read_word_dict_file(dict_fp + 'negative.p')\n",
    "    all_word_dict = read_word_dict_file(dict_fp + 'all.p')\n",
    "    \n",
    "    return (positive_dict, negative_dict, all_word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score and Label CMSC Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmsc_dict_fp = './data/word_lists/cmsc_'\n",
    "cmsc_sentiment_df = all_cmsc_reviews.copy()\n",
    "\n",
    "# If the reviews don't have sentiment scoring/label, then do so\n",
    "if reviews_need_sentiment(cmsc_sentiment_df):\n",
    "    (cmsc_sentiment_df, \n",
    "     cmsc_positive_dict, \n",
    "     cmsc_negative_dict, \n",
    "     cmsc_all_word_dict) = score_and_label_reviews(cmsc_sentiment_df, 'cmsc', cmsc_dict_fp)\n",
    "    \n",
    "# Otherwise, just read in the word frequency dictionaries\n",
    "else:\n",
    "    (cmsc_positive_dict, \n",
    "     cmsc_negative_dict, \n",
    "     cmsc_all_word_dict) = read_word_freq_dicts(cmsc_dict_fp)\n",
    "\n",
    "cmsc_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score and Label BMGT Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmgt_dict_fp = './data/word_lists/bmgt_'\n",
    "bmgt_sentiment_df = all_bmgt_reviews.copy()\n",
    "\n",
    "# If the reviews don't have sentiment scoring/label, then do so\n",
    "if reviews_need_sentiment(bmgt_sentiment_df):\n",
    "    (bmgt_sentiment_df, \n",
    "     bmgt_positive_dict, \n",
    "     bmgt_negative_dict,\n",
    "     bmgt_all_word_dict) = score_and_label_reviews(bmgt_sentiment_df, 'bmgt', bmgt_dict_fp)\n",
    "    \n",
    "# Otherwise, just read in the word frequency dictionaries\n",
    "else:\n",
    "    (bmgt_positive_dict,\n",
    "     bmgt_negative_dict,\n",
    "     bmgt_all_word_dict) = read_word_freq_dicts(bmgt_dict_fp)\n",
    "    \n",
    "bmgt_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the Sentiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How often these types of words are used per major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the percentage of each type of word type per major\n",
    "cmsc_all_word_count = sum(cmsc_all_word_dict.values())\n",
    "cmsc_positive_pct = sum(cmsc_positive_dict.values()) / cmsc_all_word_count * 100\n",
    "cmsc_negative_pct = sum(cmsc_negative_dict.values()) / cmsc_all_word_count * 100\n",
    "\n",
    "bmgt_all_word_count = sum(bmgt_all_word_dict.values())\n",
    "bmgt_positive_pct = sum(bmgt_positive_dict.values()) / bmgt_all_word_count * 100\n",
    "bmgt_negative_pct = sum(bmgt_negative_dict.values()) / bmgt_all_word_count * 100\n",
    "\n",
    "# Put these percentages into a dataframe\n",
    "word_pct_df = pd.DataFrame(columns=['type', 'major', 'percentage'])\n",
    "\n",
    "word_pct_df = word_pct_df.append({'type': 'positive' , 'major': 'bmgt', 'percentage': bmgt_positive_pct}, ignore_index=True)\n",
    "word_pct_df = word_pct_df.append({'type': 'negative' , 'major': 'bmgt', 'percentage': bmgt_negative_pct}, ignore_index=True)\n",
    "\n",
    "word_pct_df = word_pct_df.append({'type': 'positive' , 'major': 'cmsc', 'percentage': cmsc_positive_pct}, ignore_index=True)\n",
    "word_pct_df = word_pct_df.append({'type': 'negative' , 'major': 'cmsc', 'percentage': cmsc_negative_pct}, ignore_index=True)\n",
    "\n",
    "# Display the dataframe as a bar graph\n",
    "ax = sns.catplot(x='type', y='percentage', kind='bar', hue='major', data=word_pct_df)\n",
    "ax.set(xlabel='Type of words', ylabel='Perctange of all words (%)', title='Percentage of Types of Words Per Major')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've taken the percentage of postivie and negative words from all words recorded per major. Even with these as percentages of all words per major, CMSC comes out as using more emotional language - both positive and negative - than BMGT. Though this could simply mean the lexicon used for positive and negative words didn't match up to the BMGT reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings and Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "reg = LinearRegression().fit(all_reviews[['sentiment_score']], all_reviews['rating'])\n",
    "slope = reg.coef_[0]\n",
    "intercept = reg.intercept_\n",
    "plt.scatter(all_reviews['sentiment_score'], all_reviews['rating'])\n",
    "lin = \"y = \" + str(slope) + \"x \" + '+ ' + str(intercept)\n",
    "\n",
    "plt.plot(all_reviews['sentiment_score'], intercept + slope*all_reviews['sentiment_score'], \"r\", label=lin)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Correlation between Sentiment and Rating')\n",
    "plt.legend(loc='upper left', prop={'size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphing a regression between ratings and sentiment score for ALL REVIEWS, we see a modest correlation of 0.22, meaning that reviews with positive sentiment are associated with higher starred reviews. This suggests our rudimentary sentiment analysis is somewhat accurate. When points have a sentiment of -20 (the outlier), that means that there were 20 more words in the review that matched our \"negative connotation\" dictionary than our positive one; the opposite is true for values on the other end of the sentiment spectrum. The points are evenly spaced out because of the discreteness of the sentiment analysis and ratings system -- people can only give ratings in increments of 0.5 between 1 and 5 stars, and our sentiment score can only be an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Dispersion and Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the pertinent columns and get the month, year, and semester for each date\n",
    "sentiment_time = all_reviews[['date', 'major', 'source', 'rating', 'sentiment_ground_label']].copy().dropna()\n",
    "sentiment_time['month'] = sentiment_time['date'].apply(lambda date: get_month_from_unix(date))\n",
    "sentiment_time['year'] = sentiment_time['date'].apply(lambda date: get_year_from_unix(date))\n",
    "sentiment_time['year'] = sentiment_time['year'].astype(int)\n",
    "\n",
    "# Need to make month categorical to make it ordered in the graph\n",
    "sentiment_time['month'] = sentiment_time['month'].astype(month_type)\n",
    "\n",
    "# Need to make semester categorical to make it ordered in the graph\n",
    "sentiment_time['semester'] = sentiment_time['date'].apply(lambda date: get_semester_from_unix(date))\n",
    "sentiment_time['semester'] = sentiment_time['semester'].astype(semester_type)\n",
    "\n",
    "sentiment_time.loc[sentiment_time['source'] == 'rmp', 'full_source'] = 'RateMyProfessor'\n",
    "sentiment_time.loc[sentiment_time['source'] == 'pt', 'full_source'] = 'PlanetTerp'\n",
    "\n",
    "sentiment_year = sentiment_time.sort_values(by='year')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "sns.violinplot(x='year', y='sentiment_ground_label', data=sentiment_year, ax=ax)\n",
    "ax.set(xlabel='Year', ylabel='Sentiment (1 Positive, -1 Negative)', title='Sentiment Over Time')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this graph, we can see the dispersion of sentiment scores over the years. While 2013 looks optimistically positive, let's remember there were not many reviews. But at least those who were, were happy about their class or professor. Surprisingly though, most years tend towards the positive spectrum. This is a bit surprising, as generally you see negative reviews as more likely. This data could be skewed by our rudimentary labeling though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_source = sentiment_time.sort_values(by='source')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "sns.violinplot(x='sentiment_ground_label', y='full_source', hue='major', data=sentiment_source, ax=ax)\n",
    "ax.set(ylabel='Data Source', xlabel='Sentiment (1 Positive, -1 Negative)', title='Sentiment of Reviews Per Source Per Major')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the distribution of the sentiment of reviews from each website, per major. After the previous graph, it isn't too surprising to see the sentiments are more heavily on the positive spectrum. However, it is interesting to see that both majors are about equal in their sentiment distribution on both websites. It does appear less BMGT reviews are negative on RateMyProfesor, with more neutral there as well. Additionally, it appears CMSC is more heavily weighted in the negative sentiment reviews found on both PlanetTerp and RateMyProfessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_source = sentiment_time.sort_values(by='month')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 5))\n",
    "\n",
    "sns.violinplot(x='month', y='sentiment_ground_label', hue='major', data=sentiment_source, ax=ax)\n",
    "ax.set(xlabel='Data Source', ylabel='Sentiment (1 Positive, -1 Negative)', title='Sentiment of Reviews Per Month Per Major')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph depicts the dispersion of sentiment per month with the majors shown separately. March appears to have little to no spread for BMGT. Although, if we look at the review count per month graph above, we see that not many reviews are posted in March. May and December, the two most posted months, appear to maintain the positivity streak too. This positivity trend seems to dominate, barring February and August."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Word Associations and Sentiments with WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(word_freq_dict):\n",
    "    \"\"\"Creates a single WordCloud given the word frequency dictionary.\n",
    "    \n",
    "    Args:\n",
    "        word_freq_dict: A dictionary of word frequencies.\n",
    "        \n",
    "    Returns:\n",
    "        A WordCloud object created from the provided dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    wc = WordCloud(background_color=\"white\", max_words=100)\n",
    "    wc.generate_from_frequencies(word_freq_dict)\n",
    "    \n",
    "    return wc\n",
    "    \n",
    "    \n",
    "def plot_multiple_wordclouds(titles, word_freq_dicts):\n",
    "    \"\"\"Creates a wordcloud for each word frequency dictionary into a \n",
    "    3 x 1 subplot figure. Titles must be the same length as the dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        titles: Title of each plot/word cloud.\n",
    "        word_freq_dicts: List of word frequency dictionaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    figure, ax = plt.subplots(1, 3, figsize=(30, 10))\n",
    "    \n",
    "    for idx in range(len(word_freq_dicts)):\n",
    "        ax[idx].imshow(create_wordcloud(word_freq_dicts[idx]))\n",
    "        ax[idx].axis('off')\n",
    "        ax[idx].set_title(titles[idx], fontdict={'fontsize': 23})\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMSC Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_wordclouds(['Positive', 'Negative', 'All'], [cmsc_positive_dict, cmsc_negative_dict, cmsc_all_word_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMGT Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_wordclouds(['Positive', 'Negative', 'All'], [bmgt_positive_dict, bmgt_negative_dict, bmgt_all_word_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've made a wordcloud for the CMSC and BMGT reviews. They have been divided up into positive, negative, and all words used. We have shown the 50 most used words in each category. Keep in mind these are the lemmas, and not necessarily the exact word form shown in the reviews. With these wordclouds we can see the many similarities between the words in each sentiment category - not too surprising. It seems both majors can be seen as good, great, and easy. And both can be seen as hard, bad,  difficult, and tough. So, sorry if you were hoping your major saying only 'AWESOME' in the largest font. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 Most Common Words and their Frequencies, by Major and by Connotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_and_connotation=[cmsc_positive_dict, bmgt_positive_dict, cmsc_negative_dict, bmgt_negative_dict]\n",
    "titles=[\"CMSC Positive\", \"BMGT Positive\", \"CMSC Negative\", \"BMGT Negative\"]\n",
    "colors = ['green', 'green', 'red', 'red']\n",
    "#Take top 10 most common words, make bar plot of their frequencies\n",
    "graph_num=1\n",
    "row = 0\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for dataset in major_and_connotation:\n",
    "    top = sorted(dataset.items(), key=lambda x:x[1],reverse=True)\n",
    "    words=[i[0] for i in top[:10]]\n",
    "    counts=[i[1] for i in top[:10]]\n",
    "    \n",
    "    ax = plt.subplot(2, 2, graph_num)\n",
    "    \n",
    "    plt.bar(words, counts,color=colors[graph_num - 1])\n",
    "    #Define bar plot labels\n",
    "    ax.set(xlabel='Word', ylabel='Count', title='10 Most Common ' + titles[graph_num - 1] + ' Words and their Frequencies')\n",
    "    \n",
    "    graph_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above barplots show the frequencies of the 10 most common words used in the reviews we analyzed, which is bit more easier to analyze than the Wordcloud (although less pretty). Unsurprisingly, 'good' and 'bad' are the most popular in their respective categories across majors. While there is little difference between the majors in their positive words, there is more variation in the negative words. There we see 'annoying' and 'rude' in CMSC, while 'tricky' and 'cheat' show up in BMGT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing - Predicting Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we labeled each review with a sentiment ground label. This was done in a rudimentary manner, which programmatically labeled the reviews for us based on the number of positive and negative words found in the review. Using the labels assigned to the reviews, we are going to train a model to identify a review as positive or negative. We won't be classifying neutral comments, as these can be tricky to truly classify - even without using a rudimentary labeling style that we used. Additionally, [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) only allows for a binary classification (although a one-to-many strategy could be done as well). Further information about [working with text data can be found here](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) and [here](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used in our model training pipeline which simply \n",
    "# cleans the data for us, which will be the first step in the pipeline\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "# Cleaning is simply stripping any spaces and making the text lowercase\n",
    "def clean_text(text):\n",
    "    return text.strip().lower()\n",
    "\n",
    "# We use the Bag of Words strategy to represent each review\n",
    "# Each review can now be seen as simply a vector of word frequencies\n",
    "bag_of_words = CountVectorizer(tokenizer=tokenize_lemmatize_text, ngram_range=(1,1))\n",
    "\n",
    "# Here we remove all neutral labeled reviews\n",
    "all_reviews['sentiment_ground_label'] = all_reviews['sentiment_ground_label'].astype('int')\n",
    "sentiment_df = all_reviews[all_reviews['sentiment_ground_label'].isin([1, -1])]\n",
    "\n",
    "# The data is the review's body, and the label is in sentiment_ground_label\n",
    "X = sentiment_df['body']\n",
    "y = sentiment_df['sentiment_ground_label']\n",
    "y = ylabels.astype('int')\n",
    "\n",
    "# We use Sklearn's train_test_split function to split up our data for us\n",
    "# We opted for 75% of the data to be used for training and 25% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# We'll be using LogiticRegression to classify the reviews into the correct\n",
    "# category (sentiment)\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# The model pipeline\n",
    "# First the reviews are cleaned (transformed)\n",
    "# Then they are vectorized via the bag of words method\n",
    "# Then they are classified into a sentiment with logistic regression\n",
    "pipe = Pipeline([('cleaner', predictors()),\n",
    "                ('vectorizer', bow_vector),\n",
    "                ('classifier', classifier)])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pipe.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this run, we achieved a ~84% accuracy, ~86% precision and ~91% recall. [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) describes how often it predicted correctly. The [precision percentage](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) is (true positive / (true positive + false positive)), which determines how well it predicted a sentiment was actually positive. Finally the [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) is (true positive / (true positive + false negative)) and determines the model's ability to find all positive reviews.\n",
    "\n",
    "Now if we (or you) were you feed in new reviews without any sentiment labeling, the model could predict with a high accuracy if the review was positive or negative! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Insights and Conclusion](#Insights-and-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthy to consider possible sources of bias inside our data set. One bias at play is self-selection bias -- the bias that people who have had negative experiences are more likely to respond on surveys or polls. In the case of RateMyProfessor, this is almost certainly influential -- students who received their first bad grade, or first conflict with a professor, are more likely to express and vent their frustration than students who have had relatively plain or positive experiences. Furthermore, the aggregate of all reviews from each major yielded about 2x more CS students than BMGT students (726 CS to 387 BMGT) -- for one reason or another, CS students are more represented on these online websites (participation bias). Although we normalized for these (accounting for percentages of reviews positive/negative, rather than total counts), the sample size may not be perfectly representative of the population as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of Self-Selection Bias\n",
    "Image(\"img/angry_review.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Potential Future Work](#Potential-Future-Work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future research can be divided into two categories, (1) improving the accuracy, models, and analysis of this current work, or (2) expanding the scope of the research, seeking to answer broader questions.\n",
    "\n",
    "Improvements could seek to gage how representative the PlanetTerp reviews are, by comparing them to the actual course data recorded by UMD (although this would require special permissions to access data about course grade distributions in the past). Furthermore, improvements to the NLP model can be made -- our training data set was rudimentary in its generation, by simply counting positive/negative word frequencies -- a deeper, more accurate model could increase overall accuracy and validity of our training data before it enters the Machine Learning phase. \n",
    "\n",
    "Ideas for expansion could consider more majors at UMD, and seek to answer questions about more general trends -- how do STEM majors compare in course reviews to those of Humanities subjects? Which professors are the \"most likable\" in all of UMD? Eventually, once the models are good enough, they can even be extracted to consider other Universities with comparatively little extra work -- just employ the same models on similar websites (RateMyProfessor techniques and models can be recycled, as the website stores data for most universities). How do the mean grades of introductory CS classes at UMD compare to those of CS classes at UC Berkeley? Are CS students overrepresented at those campuses as well? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
